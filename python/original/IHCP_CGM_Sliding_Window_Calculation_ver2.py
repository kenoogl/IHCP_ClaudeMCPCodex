# -*- coding: utf-8 -*-
"""
Created on Tue Aug 19 20:18:01 2025

@author: SHI ZHENGQI

Final Version of Inverse Heat Conduction Problem by using The Conjugate Gradient Mtehod: CGM

-1- Read Matlab Files whitch were generated by the IR Camera in matlab format
-2- Poly Fit the Thermal Properties (heat conductivity & specific heat)
-3- Direct Solver for heat transfer equation
-4- Adjoint Solver for CGM
-5- surface heat flux inverse calculation for a single calculation window
-6- surface heat flux inverse calculation for the whole time domain 

"""

import re
import os
import time
from pathlib import Path
from math import sin, radians

import numpy as np
import pandas as pd

from numba import njit, prange
from scipy.io import loadmat

from scipy.sparse.linalg import LinearOperator,cg
from scipy.sparse import diags
import warnings
import psutil
import gc

BASE_DIR = Path(__file__).resolve().parent

# === Reading and Poly-Fitting Thermal Properties for SUS304 === #
Thermal_properties_file_path = BASE_DIR / "metal_thermal_properties.csv"
# Thermal_properties_file_path = "D:/HT_Calculation_Python\\thermal_properties_SUS304\\metal_thermal_properties.csv"
# Thermal_properties_file_path = "C:/HT_Calculation_Python\\thermal_properties_SUS304\\metal_thermal_properties.csv"
sus304_data = pd.read_csv(Thermal_properties_file_path)

sus304_temp = sus304_data['Temperature/K'].values
sus304_rho = sus304_data['Density'].values
sus304_cp = sus304_data['Specific_Heat'].values
sus304_k = sus304_data['Thermal_Conductivity'].values

# Getting the 3-rd Poly Fiiting Factors for Density/Specific Heat/Thermal Conductivity
rho_coeffs = np.polyfit(sus304_temp, sus304_rho, 3)
cp_coeffs = np.polyfit(sus304_temp, sus304_cp, 3)
k_coeffs  = np.polyfit(sus304_temp, sus304_k,  3)
# Result = [a,b,c,d] for y = ax^3 + bx^2 + cx + d

# Poly-fit Result Calculation Unit / Return result = ax^3 + bx^2 + cx + d
@njit
def polyval_numba(coeffs, x):
    result = 0.0
    for i in range(len(coeffs)):
        result += coeffs[i] * x ** (len(coeffs) - i - 1)
    return result

@njit(parallel = True)
def thermal_properties_calculator(Temperature, cp_coeffs, k_coeffs):
    
    ni, nj, nk = Temperature.shape
    cp = np.empty((ni, nj, nk))
    k = np.empty((ni, nj, nk))

    for i in prange(ni):
        for j in range(nj):
            for k_ijk in range(nk):
                
                T_current = Temperature[i, j, k_ijk]
                cp[i, j, k_ijk] = polyval_numba(cp_coeffs, T_current)
                k[i, j, k_ijk] = polyval_numba(k_coeffs, T_current)
                
    return cp, k

rho = polyval_numba(rho_coeffs, 225 + 273.15)

# ==========================================================================
# === 数値異常検出システム (Numerical Anomaly Detection System) ===
# ==========================================================================

@njit
def check_field_finite(field):
    """
    フィールドの有限性チェック（高速版）

    Parameters:
    -----------
    field : numpy.ndarray
        検査対象のフィールド

    Returns:
    --------
    bool : すべて有限の場合True
    """
    flat_field = field.ravel()
    for i in range(flat_field.size):
        if not np.isfinite(flat_field[i]):
            return False
    return True

@njit
def check_temperature_range(T, min_temp=150.0, max_temp=3000.0):
    """
    温度場の物理的範囲チェック（高速版）

    Parameters:
    -----------
    T : numpy.ndarray
        温度場 [K]
    min_temp : float
        最小許容温度 [K]
    max_temp : float
        最大許容温度 [K]

    Returns:
    --------
    bool : 範囲内の場合True
    float : 最小値
    float : 最大値
    """
    flat_T = T.ravel()
    min_val = flat_T[0]
    max_val = flat_T[0]

    for i in range(flat_T.size):
        val = flat_T[i]
        if val < min_val:
            min_val = val
        if val > max_val:
            max_val = val

    is_valid = (min_val >= min_temp) and (max_val <= max_temp)
    return is_valid, min_val, max_val

@njit
def check_flux_range(q, max_abs_flux=1e7):
    """
    熱流束の範囲チェック（高速版）

    Parameters:
    -----------
    q : numpy.ndarray
        熱流束 [W/m²]
    max_abs_flux : float
        最大許容絶対値 [W/m²]

    Returns:
    --------
    bool : 範囲内の場合True
    float : 最小値
    float : 最大値
    """
    flat_q = q.ravel()
    min_val = flat_q[0]
    max_val = flat_q[0]

    for i in range(flat_q.size):
        val = flat_q[i]
        if val < min_val:
            min_val = val
        if val > max_val:
            max_val = val

    max_abs = max(abs(min_val), abs(max_val))
    is_valid = max_abs <= max_abs_flux
    return is_valid, min_val, max_val

@njit
def check_gradient_magnitude(field, dx, dy, dz, max_grad_temp=5000.0, max_grad_flux=1e8):
    """
    空間勾配の大きさチェック（高速版）

    Parameters:
    -----------
    field : numpy.ndarray
        フィールド（温度または熱流束）
    dx, dy : float
        x, y方向の格子間隔 [m]
    dz : numpy.ndarray
        z方向の格子間隔配列 [m]
    max_grad_temp : float
        温度勾配の最大許容値 [K/m]
    max_grad_flux : float
        熱流束勾配の最大許容値 [W/m³]

    Returns:
    --------
    bool : 許容範囲内の場合True
    float : 最大勾配値
    """
    if field.ndim == 2:
        # 2次元フィールド（表面熱流束）
        ni, nj = field.shape
        max_grad = 0.0

        # x方向勾配
        for i in range(ni-1):
            for j in range(nj):
                grad = abs(field[i+1, j] - field[i, j]) / dy  # 注：i方向がy物理方向
                if grad > max_grad:
                    max_grad = grad

        # y方向勾配
        for i in range(ni):
            for j in range(nj-1):
                grad = abs(field[i, j+1] - field[i, j]) / dx  # 注：j方向がx物理方向
                if grad > max_grad:
                    max_grad = grad

        is_valid = max_grad <= max_grad_flux

    elif field.ndim == 3:
        # 3次元フィールド（温度場）
        ni, nj, nk = field.shape
        max_grad = 0.0

        # x方向勾配
        for i in range(ni-1):
            for j in range(nj):
                for k in range(nk):
                    grad = abs(field[i+1, j, k] - field[i, j, k]) / dy
                    if grad > max_grad:
                        max_grad = grad

        # y方向勾配
        for i in range(ni):
            for j in range(nj-1):
                for k in range(nk):
                    grad = abs(field[i, j+1, k] - field[i, j, k]) / dx
                    if grad > max_grad:
                        max_grad = grad

        # z方向勾配
        for i in range(ni):
            for j in range(nj):
                for k in range(nk-1):
                    grad = abs(field[i, j, k+1] - field[i, j, k]) / dz[k]
                    if grad > max_grad:
                        max_grad = grad

        is_valid = max_grad <= max_grad_temp
    else:
        # サポートされていない次元
        return False, 0.0

    return is_valid, max_grad

def detect_numerical_anomalies(field, field_name, iteration=None, timestep=None,
                                temperature_range=(150.0, 3000.0), flux_range=(-1e7, 1e7),
                                dx=0.12e-3, dy=0.12e-3*0.866, dz=None):
    """
    数値計算における異常値を包括的に検出

    Parameters:
    -----------
    field : numpy.ndarray
        検査対象の物理場
    field_name : str
        フィールド名（温度場、熱流束、勾配等）
    iteration : int, optional
        CGM反復回数
    timestep : int, optional
        時間ステップ
    temperature_range : tuple
        温度の物理的範囲 [K]
    flux_range : tuple
        熱流束の物理的範囲 [W/m²]
    dx, dy : float
        x, y方向の格子間隔 [m]
    dz : numpy.ndarray, optional
        z方向の格子間隔配列 [m]

    Returns:
    --------
    bool : 異常が検出された場合True
    list : 検出された異常のリスト
    """
    anomalies = []

    # 1. NaN/Inf値チェック
    if not check_field_finite(field):
        anomalies.append(f"NaN/Inf値検出")

    # 2. フィールド種類別の詳細チェック
    if "温度" in field_name or "Temperature" in field_name or "T_" in field_name:
        # 温度場の検査
        is_valid, min_val, max_val = check_temperature_range(field, temperature_range[0], temperature_range[1])
        if not is_valid:
            if min_val < temperature_range[0]:
                anomalies.append(f"異常低温検出: min={min_val:.1f}K < {temperature_range[0]}K")
            if max_val > temperature_range[1]:
                anomalies.append(f"異常高温検出: max={max_val:.1f}K > {temperature_range[1]}K")

        # 温度勾配チェック
        if dz is not None:
            is_grad_valid, max_grad = check_gradient_magnitude(field, dx, dy, dz, max_grad_temp=5000.0)
            if not is_grad_valid:
                anomalies.append(f"異常な温度勾配: {max_grad:.1f}K/m > 5000K/m")

    elif "熱流束" in field_name or "flux" in field_name or "q_" in field_name or field_name == "q":
        # 熱流束場の検査
        is_valid, min_val, max_val = check_flux_range(field, max(abs(flux_range[0]), abs(flux_range[1])))
        if not is_valid:
            max_abs = max(abs(min_val), abs(max_val))
            anomalies.append(f"異常な熱流束: max_abs={max_abs:.2e}W/m² > {max(abs(flux_range[0]), abs(flux_range[1])):.2e}W/m²")

        # 熱流束勾配チェック（2次元の場合）
        if field.ndim == 2:
            is_grad_valid, max_grad = check_gradient_magnitude(field, dx, dy, np.array([0.0]), max_grad_flux=1e8)
            if not is_grad_valid:
                anomalies.append(f"異常な熱流束勾配: {max_grad:.2e}W/m³ > 1e8W/m³")

    elif "lambda" in field_name or "勾配" in field_name or "gradient" in field_name:
        # 随伴場・勾配場の検査
        is_valid, min_val, max_val = check_flux_range(field, 1e10)  # より大きな許容範囲
        if not is_valid:
            max_abs = max(abs(min_val), abs(max_val))
            anomalies.append(f"異常な随伴場/勾配: max_abs={max_abs:.2e} > 1e10")

    # 3. オーバーフロー検査
    float64_max = np.finfo(np.float64).max
    field_flat = field.ravel()
    max_abs_val = np.max(np.abs(field_flat))
    if max_abs_val > float64_max * 0.1:  # float64最大値の10%を超える場合
        anomalies.append(f"数値オーバーフローの危険: max_abs={max_abs_val:.2e} > {float64_max*0.1:.2e}")

    return len(anomalies) > 0, anomalies

def handle_numerical_anomaly(field_name, anomalies, iteration=None, timestep=None,
                             suggested_action="計算パラメータの調整を検討してください"):
    """
    数値異常への対応アクション

    Parameters:
    -----------
    field_name : str
        フィールド名
    anomalies : list
        検出された異常のリスト
    iteration : int, optional
        CGM反復回数
    timestep : int, optional
        時間ステップ
    suggested_action : str
        推奨対応策
    """
    timestamp = ""
    if iteration is not None:
        timestamp += f"[CGM反復{iteration}]"
    if timestep is not None:
        timestamp += f"[時間ステップ{timestep}]"

    print("\n" + "="*80)
    print(f"🚨 数値異常検出アラート: {field_name} {timestamp}")
    print("="*80)

    for i, anomaly in enumerate(anomalies, 1):
        print(f"{i:2d}. {anomaly}")

    print("-"*80)
    print(f"📋 推奨対応策: {suggested_action}")
    print("="*80)

    # 重大な異常の場合は追加警告
    critical_keywords = ["NaN", "Inf", "オーバーフロー"]
    if any(keyword in anomaly for anomaly in anomalies for keyword in critical_keywords):
        print("⚠️  重大: 計算の継続は危険です。パラメータの見直しを強く推奨します。")
        print("="*80)

def check_temperature_field(T, timestep=None, dx=0.12e-3, dy=0.12e-3*0.866, dz=None):
    """
    温度場の包括的チェック

    Parameters:
    -----------
    T : numpy.ndarray
        温度場 [K]
    timestep : int, optional
        時間ステップ
    dx, dy : float
        格子間隔 [m]
    dz : numpy.ndarray, optional
        z方向格子間隔配列 [m]

    Returns:
    --------
    bool : 異常検出時False
    str : 状態メッセージ
    """
    has_anomaly, anomalies = detect_numerical_anomalies(
        T, "温度場", timestep=timestep, dx=dx, dy=dy, dz=dz
    )

    if has_anomaly:
        handle_numerical_anomaly("温度場", anomalies, timestep=timestep,
                                suggested_action="時間刻みの縮小またはメッシュ調整を検討")
        return False, f"異常検出: {len(anomalies)}件"

    return True, "正常"

def check_flux_field(q, iteration=None, timestep=None, dx=0.12e-3, dy=0.12e-3*0.866):
    """
    熱流束場の包括的チェック

    Parameters:
    -----------
    q : numpy.ndarray
        熱流束場 [W/m²]
    iteration : int, optional
        CGM反復回数
    timestep : int, optional
        時間ステップ
    dx, dy : float
        格子間隔 [m]

    Returns:
    --------
    bool : 異常検出時False
    str : 状態メッセージ
    """
    has_anomaly, anomalies = detect_numerical_anomalies(
        q, "熱流束", iteration=iteration, timestep=timestep, dx=dx, dy=dy
    )

    if has_anomaly:
        handle_numerical_anomaly("熱流束", anomalies, iteration=iteration, timestep=timestep,
                                suggested_action="CGMステップサイズの調整またはモデルパラメータの見直し")
        return False, f"異常検出: {len(anomalies)}件"

    return True, "正常"

def check_adjoint_field(lambda_field, iteration=None, timestep=None, dx=0.12e-3, dy=0.12e-3*0.866, dz=None):
    """
    随伴場の包括的チェック

    Parameters:
    -----------
    lambda_field : numpy.ndarray
        随伴場
    iteration : int, optional
        CGM反復回数
    timestep : int, optional
        時間ステップ
    dx, dy : float
        格子間隔 [m]
    dz : numpy.ndarray, optional
        z方向格子間隔配列 [m]

    Returns:
    --------
    bool : 異常検出時False
    str : 状態メッセージ
    """
    has_anomaly, anomalies = detect_numerical_anomalies(
        lambda_field, "随伴場lambda", iteration=iteration, timestep=timestep, dx=dx, dy=dy, dz=dz
    )

    if has_anomaly:
        handle_numerical_anomaly("随伴場", anomalies, iteration=iteration, timestep=timestep,
                                suggested_action="CGM収束条件の緩和または反復回数の制限")
        return False, f"異常検出: {len(anomalies)}件"

    return True, "正常"

def handle_critical_anomaly(field_name, iteration=None, timestep=None, emergency_stop=True):
    """
    重大な数値異常への緊急対応

    Parameters:
    -----------
    field_name : str
        異常が検出されたフィールド名
    iteration : int, optional
        CGM反復回数
    timestep : int, optional
        時間ステップ
    emergency_stop : bool
        緊急停止を実行するかどうか

    Returns:
    --------
    bool : 計算を停止すべきかどうか
    """
    timestamp = ""
    if iteration is not None:
        timestamp += f"[CGM反復{iteration}]"
    if timestep is not None:
        timestamp += f"[時間ステップ{timestep}]"

    print("\n" + "="*90)
    print(f"🔴 重大異常検出 - 緊急停止モード {timestamp}")
    print("="*90)
    print(f"異常箇所: {field_name}")
    print(f"検出時刻: {timestamp}")
    print("-"*90)
    print("重大異常の種類:")
    print("  • NaN/Inf値の検出")
    print("  • 数値オーバーフロー")
    print("  • 物理的に不可能な値")
    print("-"*90)
    print("緊急対応策:")
    print("  1. 計算の即座停止")
    print("  2. 現在の結果の保存")
    print("  3. パラメータの見直し")
    print("  4. より厳しい安定性条件での再開")
    print("="*90)

    if emergency_stop:
        print("🚨 緊急停止を実行します。")
        return True
    else:
        print("⚠️  警告のみ。計算を継続します。")
        return False

def enhanced_anomaly_response(field, field_name, anomalies, iteration=None, timestep=None,
                              auto_stop_critical=True):
    """
    拡張された異常対応システム

    Parameters:
    -----------
    field : numpy.ndarray
        異常が検出されたフィールド
    field_name : str
        フィールド名
    anomalies : list
        検出された異常のリスト
    iteration : int, optional
        CGM反復回数
    timestep : int, optional
        時間ステップ
    auto_stop_critical : bool
        重大異常時の自動停止を有効にするか

    Returns:
    --------
    bool : 計算停止が必要かどうか
    dict : 診断情報
    """
    # 重大異常のキーワード
    critical_keywords = ["NaN", "Inf", "オーバーフロー"]

    # 重大度の分類
    has_critical = any(keyword in anomaly for anomaly in anomalies for keyword in critical_keywords)
    has_physical_violation = any("異常低温" in anomaly or "異常高温" in anomaly or "物理的" in anomaly for anomaly in anomalies)
    has_extreme_gradient = any("勾配" in anomaly for anomaly in anomalies)

    diagnosis = {
        "severity": "normal",
        "anomaly_count": len(anomalies),
        "has_critical": has_critical,
        "has_physical_violation": has_physical_violation,
        "has_extreme_gradient": has_extreme_gradient,
        "field_stats": {
            "min": float(np.min(field)),
            "max": float(np.max(field)),
            "mean": float(np.mean(field)),
            "std": float(np.std(field))
        },
        "recommendations": []
    }

    # 重大度の判定と対応
    if has_critical:
        diagnosis["severity"] = "critical"
        diagnosis["recommendations"].extend([
            "即座に計算を停止してください",
            "数値スキームの見直しが必要です",
            "時間刻みを大幅に縮小してください"
        ])

        if auto_stop_critical:
            should_stop = handle_critical_anomaly(field_name, iteration, timestep, emergency_stop=True)
            diagnosis["auto_stopped"] = should_stop
            return should_stop, diagnosis

    elif has_physical_violation:
        diagnosis["severity"] = "severe"
        diagnosis["recommendations"].extend([
            "物理パラメータの見直しを検討",
            "境界条件の確認",
            "材料物性値の妥当性チェック"
        ])

    elif has_extreme_gradient:
        diagnosis["severity"] = "moderate"
        diagnosis["recommendations"].extend([
            "メッシュの細分化を検討",
            "空間離散化精度の向上",
            "勾配リミッターの導入"
        ])

    # 標準的な異常処理
    handle_numerical_anomaly(field_name, anomalies, iteration, timestep)

    diagnosis["auto_stopped"] = False
    return False, diagnosis

# ==========================================================================
# === メモリ使用量監視システム (Memory Usage Monitoring System) ===
# ==========================================================================

def get_memory_info():
    """
    システムメモリ情報の取得

    Returns:
    --------
    dict : メモリ情報辞書
        'rss_gb': 実メモリ使用量 [GB]
        'vms_gb': 仮想メモリ使用量 [GB]
        'available_gb': 利用可能メモリ [GB]
        'total_gb': 総メモリ容量 [GB]
        'percent': メモリ使用率 [%]
    """
    try:
        process = psutil.Process()
        memory_info = process.memory_info()
        system_memory = psutil.virtual_memory()

        return {
            'rss_gb': memory_info.rss / (1024**3),
            'vms_gb': memory_info.vms / (1024**3),
            'available_gb': system_memory.available / (1024**3),
            'total_gb': system_memory.total / (1024**3),
            'percent': system_memory.percent
        }
    except Exception as e:
        print(f"⚠️ メモリ情報取得エラー: {e}")
        return {
            'rss_gb': 0.0, 'vms_gb': 0.0, 'available_gb': 0.0,
            'total_gb': 0.0, 'percent': 0.0
        }

def safe_file_size_check(filepath):
    """
    ファイルサイズの安全性チェック

    Parameters:
    -----------
    filepath : str or Path
        ファイルパス

    Returns:
    --------
    float : ファイルサイズ [GB]

    Raises:
    -------
    FileNotFoundError : ファイルが存在しない場合
    """
    filepath = Path(filepath)
    if not filepath.exists():
        raise FileNotFoundError(f"ファイルが見つかりません: {filepath}")

    file_size_gb = filepath.stat().st_size / (1024**3)
    return file_size_gb

def monitor_memory_usage(stage_name="", warning_threshold_gb=6.0, critical_threshold_gb=8.0):
    """
    現在のメモリ使用量を監視し、必要に応じて警告を表示

    Parameters:
    -----------
    stage_name : str
        計算段階の名前
    warning_threshold_gb : float
        警告レベルのメモリ使用量 [GB]
    critical_threshold_gb : float
        危険レベルのメモリ使用量 [GB]

    Returns:
    --------
    float : 現在のメモリ使用量 [GB]
    bool : 危険レベルに達した場合True
    """
    memory_info = get_memory_info()
    current_gb = memory_info['rss_gb']

    print(f"📊 [{stage_name}] メモリ使用状況:")
    print(f"   プロセス使用量: {current_gb:.2f}GB")
    print(f"   システム利用可能: {memory_info['available_gb']:.2f}GB")
    print(f"   システム使用率: {memory_info['percent']:.1f}%")

    # 危険レベル判定
    is_critical = current_gb > critical_threshold_gb
    is_warning = current_gb > warning_threshold_gb

    if is_critical:
        print(f"🚨 【危険】メモリ使用量が危険レベルに到達!")
        print(f"   {current_gb:.2f}GB > {critical_threshold_gb:.2f}GB")
        print(f"   推奨対応: 即座にメモリ最適化またはプロセス停止")
        return current_gb, True

    elif is_warning:
        print(f"⚠️ 【警告】メモリ使用量が警告レベルに到達")
        print(f"   {current_gb:.2f}GB > {warning_threshold_gb:.2f}GB")
        print(f"   推奨対応: ガベージコレクション実行")
    else:
        print(f"✅ メモリ使用量正常")

    return current_gb, is_critical

def safe_load_large_data(filepath, max_size_gb=2.0, memory_check=True):
    """
    メモリ枯渇を防ぐ安全なデータ読み込み

    Parameters:
    -----------
    filepath : str or Path
        読み込むファイルのパス
    max_size_gb : float
        許可する最大ファイルサイズ [GB]
    memory_check : bool
        メモリ使用量事前チェックを行うか

    Returns:
    --------
    numpy.ndarray : 読み込まれたデータ

    Raises:
    -------
    MemoryError : メモリ不足の場合
    ValueError : ファイルサイズが大きすぎる場合
    """
    filepath = Path(filepath)

    print(f"📁 大容量データの安全読み込み開始: {filepath.name}")

    # ファイルサイズチェック
    try:
        file_size_gb = safe_file_size_check(filepath)
        print(f"   ファイルサイズ: {file_size_gb:.3f}GB")

        if file_size_gb > max_size_gb:
            raise ValueError(f"ファイルサイズが大きすぎます: {file_size_gb:.3f}GB > {max_size_gb:.3f}GB")

    except FileNotFoundError as e:
        print(f"❌ {e}")
        raise

    # メモリ使用量事前チェック
    if memory_check:
        current_memory, is_critical = monitor_memory_usage("読み込み前",
                                                         warning_threshold_gb=6.0,
                                                         critical_threshold_gb=8.0)

        # 利用可能メモリと必要メモリの比較
        memory_info = get_memory_info()
        available_gb = memory_info['available_gb']

        # 経験則：numpyファイルは約1.5倍のメモリを一時的に使用
        estimated_memory_gb = file_size_gb * 1.5

        if estimated_memory_gb > available_gb * 0.8:  # 利用可能メモリの80%以下
            print(f"⚠️ メモリ不足の警告:")
            print(f"   推定必要メモリ: {estimated_memory_gb:.2f}GB")
            print(f"   利用可能メモリ: {available_gb:.2f}GB")

            # 自動的なメモリ最適化を試行
            print("📋 自動メモリ最適化を実行中...")
            optimize_memory_usage(force_gc=True, compact_arrays=False)

            # 再チェック
            memory_info_after = get_memory_info()
            available_after = memory_info_after['available_gb']

            if estimated_memory_gb > available_after * 0.8:
                raise MemoryError(f"メモリ不足: 必要{estimated_memory_gb:.2f}GB > 利用可能{available_after:.2f}GB")

    # データ読み込み実行
    try:
        print("💾 データ読み込み実行中...")
        data = np.load(filepath)
        print(f"✅ 読み込み成功: shape={data.shape}, dtype={data.dtype}")

        # 読み込み後のメモリ状況確認
        if memory_check:
            monitor_memory_usage("読み込み後", warning_threshold_gb=6.0, critical_threshold_gb=8.0)

        return data

    except Exception as e:
        print(f"❌ データ読み込みエラー: {e}")
        raise MemoryError(f"データ読み込み失敗: {e}")

def optimize_memory_usage(force_gc=True, compact_arrays=False):
    """
    メモリ使用量の最適化

    Parameters:
    -----------
    force_gc : bool
        強制ガベージコレクションを実行
    compact_arrays : bool
        配列の再配置によるメモリ最適化（実装予約）
    """
    print("🔧 メモリ最適化を実行中...")

    # 最適化前のメモリ状況
    before_info = get_memory_info()
    before_gb = before_info['rss_gb']

    if force_gc:
        print("   - ガベージコレクション実行...")
        collected = gc.collect()
        print(f"   - 回収オブジェクト数: {collected}")

    # 最適化後のメモリ状況
    after_info = get_memory_info()
    after_gb = after_info['rss_gb']
    saved_gb = before_gb - after_gb

    print(f"📊 最適化結果:")
    print(f"   最適化前: {before_gb:.2f}GB")
    print(f"   最適化後: {after_gb:.2f}GB")
    print(f"   削減量: {saved_gb:.2f}GB ({saved_gb/before_gb*100:.1f}%)")

def memory_warning_system(current_gb, threshold_gb, stage_name):
    """
    メモリ使用量警告システム

    Parameters:
    -----------
    current_gb : float
        現在のメモリ使用量 [GB]
    threshold_gb : float
        警告閾値 [GB]
    stage_name : str
        計算段階名

    Returns:
    --------
    bool : 警告が発生した場合True
    """
    if current_gb > threshold_gb:
        print(f"\n{'='*70}")
        print(f"⚠️ メモリ警告: {stage_name}")
        print(f"   現在使用量: {current_gb:.2f}GB > 閾値{threshold_gb:.2f}GB")
        print(f"   推奨対応: ガベージコレクション実行")
        print(f"{'='*70}")

        # 自動的なメモリ最適化
        optimize_memory_usage(force_gc=True)
        return True
    return False

def check_memory_critical(current_gb, critical_gb=8.0, emergency_stop=True):
    """
    重大なメモリ不足への緊急対応

    Parameters:
    -----------
    current_gb : float
        現在のメモリ使用量 [GB]
    critical_gb : float
        危険閾値 [GB]
    emergency_stop : bool
        緊急停止を実行するかどうか

    Returns:
    --------
    bool : 計算を停止すべきかどうか
    """
    if current_gb > critical_gb:
        print(f"\n{'='*80}")
        print(f"🔴 重大メモリ不足検出 - 緊急対応モード")
        print(f"{'='*80}")
        print(f"現在のメモリ使用量: {current_gb:.2f}GB")
        print(f"危険閾値: {critical_gb:.2f}GB")
        print("-"*80)
        print("緊急対応策:")
        print("  1. 計算の即座停止")
        print("  2. 現在の結果の保存")
        print("  3. メモリ最適化の実行")
        print("  4. より小さなデータサイズでの再開")
        print(f"{'='*80}")

        if emergency_stop:
            print("🚨 緊急停止を実行します。")
            return True
        else:
            print("⚠️ 警告のみ。計算を継続します。")
            return False
    return False

# ==========================================================================

def check_diffusion_stability(dx, dy, dz_min, dt, k_max, rho_min, cp_min):
    """
    拡散数による数値安定性をチェックする関数

    Parameters:
    -----------
    dx, dy, dz_min : float
        x, y, z方向の格子サイズ [m] (dz_minは最小格子サイズ)
    dt : float
        時間刻み [s]
    k_max : float
        最大熱伝導率 [W/(m·K)]
    rho_min : float
        最小密度 [kg/m³]
    cp_min : float
        最小比熱 [J/(kg·K)]

    Returns:
    --------
    max_diff_num : float
        最大拡散数
    diff_nums : tuple
        各方向の拡散数 (diff_num_x, diff_num_y, diff_num_z)
    """
    # 最大熱拡散率の計算（最も不安定な条件）
    diffusivity_max = k_max / (rho_min * cp_min)

    # 各方向の拡散数計算
    diff_num_x = diffusivity_max * dt / (dx**2)
    diff_num_y = diffusivity_max * dt / (dy**2)
    diff_num_z = diffusivity_max * dt / (dz_min**2)

    # 最大拡散数の特定
    max_diff_num = max(diff_num_x, diff_num_y, diff_num_z)

    # 安定性判定と警告表示
    stability_threshold = 0.5  # 暗示的スキームでも推奨される上限

    print("\n" + "="*60)
    print("         拡散数による数値安定性チェック")
    print("="*60)
    print(f"使用パラメータ:")
    print(f"  時間刻み dt        : {dt:.4f} [s]")
    print(f"  格子サイズ dx      : {dx*1e3:.3f} [mm]")
    print(f"  格子サイズ dy      : {dy*1e3:.3f} [mm]")
    print(f"  最小格子 dz_min    : {dz_min*1e6:.1f} [μm]")
    print(f"  最大熱伝導率 k_max : {k_max:.2f} [W/(m·K)]")
    print(f"  最小密度 ρ_min     : {rho_min:.0f} [kg/m³]")
    print(f"  最小比熱 cp_min    : {cp_min:.1f} [J/(kg·K)]")
    print(f"  最大熱拡散率      : {diffusivity_max*1e6:.2f} [mm²/s]")
    print("-"*60)
    print(f"拡散数計算結果:")
    print(f"  x方向拡散数       : {diff_num_x:.4f}")
    print(f"  y方向拡散数       : {diff_num_y:.4f}")
    print(f"  z方向拡散数       : {diff_num_z:.4f}")
    print(f"  最大拡散数        : {max_diff_num:.4f}")
    print("-"*60)

    if max_diff_num > stability_threshold:
        print(f"⚠️  警告: 拡散数が大きすぎます!")
        print(f"   最大拡散数 {max_diff_num:.4f} > 推奨上限 {stability_threshold}")
        print(f"   数値不安定性が発生する可能性があります。")
        print()

        # 安全な時間刻みの推奨
        safe_dt_x = stability_threshold * (dx**2) / diffusivity_max
        safe_dt_y = stability_threshold * (dy**2) / diffusivity_max
        safe_dt_z = stability_threshold * (dz_min**2) / diffusivity_max
        safe_dt = min(safe_dt_x, safe_dt_y, safe_dt_z)

        print(f"推奨時間刻み:")
        print(f"  x方向制約による dt ≤ {safe_dt_x*1e3:.3f} [ms]")
        print(f"  y方向制約による dt ≤ {safe_dt_y*1e3:.3f} [ms]")
        print(f"  z方向制約による dt ≤ {safe_dt_z*1e6:.1f} [μs]")
        print(f"  推奨最大時間刻み  : {safe_dt*1e6:.1f} [μs]")
        print()

        # 実用的な対応策の提示
        print("📋 実用的な対応策:")
        if safe_dt < dt * 0.01:  # 推奨値が現在値の1/100以下の場合
            print("  1. z方向格子の粗い化（表面付近の精度とのトレードオフ）")
            print("  2. 暗示的解法の安定性に依存した計算の継続")
            print("  3. 局所的時間刻み適応法の導入")
            print("  4. アダプティブメッシュ法の検討")
        else:
            print(f"  1. 時間刻みを {safe_dt*1e3:.3f} ms以下に変更")
            print("  2. 計算コストとのバランスを考慮")

        warnings.warn(f"拡散数が推奨上限を超えています: {max_diff_num:.4f} > {stability_threshold}")
    else:
        print(f"✅ 安定性OK: 拡散数 {max_diff_num:.4f} ≤ 推奨上限 {stability_threshold}")

        # 余裕度の計算
        safety_factor = stability_threshold / max_diff_num
        print(f"   安全余裕度: {safety_factor:.2f}倍")

    print("="*60)

    return max_diff_num, (diff_num_x, diff_num_y, diff_num_z)


'''
Define the Function to Find the Files whitch can Match Name format["SUS" + number + ".MAT"]
Sort the Files by the Keys of Extract Numbers from the Small to Large
'''

def extract_sorted_mat_files(folder_path):
    def extract_number(file_name):
        match = re.match(r'SUS(\d+)\.MAT', file_name)
        return int(match.group(1)) if match else -1
    
    files = []
    for f in os.listdir(folder_path):
        if f.startswith('SUS') and f.endswith('.MAT'):
            files.append(f)
    return sorted(files, key = extract_number)

'''
Load the Temperature Variation Array of a Specific Region from IR Temperature File
Region: (i_start, j_start) to (i_end, j_end)
'''
def load_region_temperature(folder_path, i_range, j_range):
    i_start, i_end = i_range
    j_start, j_end = j_range

    mat_files = extract_sorted_mat_files(folder_path)
    num_frames = len(mat_files)
    
    height = i_end - i_start + 1
    width = j_end - j_start + 1

    region_data_K = np.zeros((height, width, num_frames))
    
    # read temperature array of a specific location from IR camera matlac files,
    # preserve the temperature data to region_data_K & region_data_C

    for idx, file in enumerate(mat_files):
        
        mat_data = loadmat(os.path.join(folder_path, file))
        frame_data = mat_data[file[:-4]]
        
        sub_region = frame_data[i_start:i_end + 1, j_start:j_end + 1]
        region_data_K[:, :, idx] = sub_region

    return region_data_K, num_frames

'''
Define the Physical properties of Calculation Region 
'''
nz = 20                                                                        # grid numbers at x, y, z direction
dx, dy = 0.12e-3, (0.12e-3 * sin(radians(80)) / sin(radians(45)))              # real x_direction & y_direction length for a single pixel 
Lz = 0.5e-3                                                                    # real x, y, z direction length
 
stretch_factor = 3   
# Grid faces plotting for Z direction
z_faces = np.linspace(1, 0, nz + 1)                                                            # Generate nz+1 grid surfaces for nz grids

# Irregular grid generation from regular grid faces
z_faces = Lz - (Lz / (np.exp(stretch_factor) - 1)) * (np.exp(stretch_factor * z_faces) - 1)    # Generate stretched grid 

z_centers = np.zeros(nz)                                  # Center coordinates for nz grids

z_centers[0] = z_faces[0]                                 # The Bottom-most grid center coordinate(half CV/ grid center point overlaps the Bottom-most boundary)
z_centers[-1] = z_faces[-1]                               # The top-most grid center coordinate(half CV/ grid center point overlaps the top-most boundary)
z_centers[1:-1] = (z_faces[1:-2] + z_faces[2:-1]) / 2     # Intermediate grids
                
# Boundary component Calculation
dz = np.diff(z_faces)                                # Calculate every-grid size

dz_t = np.zeros(nz)                                  # Top component_delta_z_t
dz_t[-1] = np.inf                                    # Top component_delta_z_t for top-most CV
dz_t[:-1] = z_centers[1:] - z_centers[:-1]           # Other Top component_delta_z_t

dz_b = np.zeros(nz)                                  # Bottom component_delta_z_b
dz_b[0] = np.inf                                     # Bottom component_delta_z_b for Bottom-most CV
dz_b[1:] = z_centers[1:] - z_centers[:-1]            # Other Bottom component_delta_z_b

# debug
print("z_faces : ", z_faces)
print("z_centers : ", z_centers)
print("dz : ", dz)
print("dz_t : ", dz_t)
print("dz_b : ", dz_b)
#

'''
=== Direct problem solver  ===
=== Sensitivity problem solver ===

coefficients(a*) for A whitch used csr_matrix (Compressed Sparse Row matrix: CSR) class
and right hand side (b) building for direct heat conduction problems for 1 time step (Ax = b)
'''
@njit(parallel=True, fastmath=False)
def coeffs_and_rhs_building_DHCP(T_initial, q_surface, rho, cp, k, dx, dy, dz, dz_b, dz_t, dt):
    ni, nj, nk = T_initial.shape
    N = ni * nj * nk
    
    a_w = np.zeros(N)
    a_e = np.zeros(N)
    a_s = np.zeros(N)
    a_n = np.zeros(N)
    a_b = np.zeros(N)
    a_t = np.zeros(N)
    a_p = np.zeros(N)
    
    b   = np.zeros(N)
    
    for p in prange(N):
        i = p % ni
        j = (p // ni) % nj
        k_ijk = p // (ni * nj)
        
        dz_k = dz[k_ijk]
        dz_t_k = dz_t[k_ijk]
        dz_b_k = dz_b[k_ijk]
        
        k_p = k[i, j, k_ijk]
        
        a_p_0 = rho * cp[i, j, k_ijk] * dx * dy * dz_k / dt
        
        a_w[p] = 0.0 if j == 0                 else (2 * k_p * k[i, j-1, k_ijk] / (k_p + k[i, j-1, k_ijk])) * dy * dz_k / dx
        a_e[p] = 0.0 if j == nj-1              else (2 * k_p * k[i, j+1, k_ijk] / (k_p + k[i, j+1, k_ijk])) * dy * dz_k / dx
        a_s[p] = 0.0 if i == 0                 else (2 * k_p * k[i-1, j, k_ijk] / (k_p + k[i-1, j, k_ijk])) * dx * dz_k / dy
        a_n[p] = 0.0 if i == ni-1              else (2 * k_p * k[i+1, j, k_ijk] / (k_p + k[i+1, j, k_ijk])) * dx * dz_k / dy
        a_b[p] = 0.0 if k_ijk == 0             else (2 * k_p * k[i, j, k_ijk-1] / (k_p + k[i, j, k_ijk-1])) * dx * dy / dz_b_k
        a_t[p] = 0.0 if k_ijk == nk-1          else (2 * k_p * k[i, j, k_ijk+1] / (k_p + k[i, j, k_ijk+1])) * dx * dy / dz_t_k
        
        a_p[p] = a_w[p] + a_e[p] + a_s[p] + a_n[p] + a_b[p] + a_t[p] + a_p_0
        
        rhs = a_p_0 * T_initial[i, j, k_ijk]
        
        if k_ijk == nk - 1:
            rhs += q_surface[i, j] * dx * dy
        b[p] = rhs
        
    return a_w, a_e, a_s, a_n, a_b, a_t, a_p, b

def assemble_A_DHCP(ni, nj, nk, a_w, a_e, a_s, a_n, a_b, a_t, a_p):
    N = ni * nj * nk
    
    off_i = 1           # offsets for i direction (south & north)
    off_j = ni          # offsets for j direction (west & east)
    off_k = ni * nj     # offsets for k direction (bottom & top)

    D0   = a_p.copy()                 # len N
    D_im1 = -a_s[off_i: ]        # len N-1
    D_jm1 = -a_w[off_j: ]        # len N-ni
    D_km1 = -a_b[off_k: ]        # len N-ni*nj
    
    D_ip1 = -a_n[ :N-off_i]         # len N-1
    D_jp1 = -a_e[ :N-off_j]         # len N-ni
    D_kp1 = -a_t[ :N-off_k]         # len N-ni*nj

    A_csr = diags(
        diagonals=[D0, D_im1, D_jm1, D_km1, D_kp1, D_jp1, D_ip1],
        offsets=[0, -off_i, -off_j, -off_k, off_k, off_j, off_i],
        shape=(N, N), format="csr"
    )
    
    return A_csr


def multiple_time_step_solver_DHCP(T_initial, q_surface, nt, rho, cp_coeffs, k_coeffs,
                                       dx, dy, dz, dz_b, dz_t, dt, rtol, maxiter):
    '''
    nt: time step number for Temperature measurement (T_measure)
    T_initial.shape = (ni, nj, nk)
    q_surface:  | heat flux on upper surface
                | shape = (nt-1, ni, nj)
    T_all: 3D Temperature distributation at every time step

    return: T_all.shape = (nt, ni, nj, nk)
    '''

    ni, nj, nk = T_initial.shape
    N = ni * nj * nk

    # 大規模問題でのメモリ監視（DHCP開始時）
    if N > 100000:  # 約10万要素以上の場合
        current_memory, is_critical = monitor_memory_usage(f"DHCP開始(N={N})",
                                                          warning_threshold_gb=6.0,
                                                          critical_threshold_gb=8.0)
        if is_critical:
            raise MemoryError("DHCP: メモリ不足により計算を停止")

    T_all = np.empty((nt, ni, nj, nk))
    T_all[0] = T_initial

    x0 = T_initial.ravel(order = "F").copy()
    
    for t in range(1, nt):
        
        cp, k = thermal_properties_calculator(T_all[t-1], cp_coeffs, k_coeffs)
        
        a_w, a_e, a_s, a_n, a_b, a_t, a_p, b = coeffs_and_rhs_building_DHCP(T_all[t-1], q_surface[t-1], rho, cp, k, dx, dy, dz, dz_b, dz_t, dt)
        
        A_csr = assemble_A_DHCP(ni, nj, nk, a_w, a_e, a_s, a_n, a_b, a_t, a_p)

        diag = A_csr.diagonal()
        inv_diag = np.where(diag != 0.0, 1.0/diag, 0.0)  # 防除零
        
        def Mv(z):
            return inv_diag * z
        
        M = LinearOperator(A_csr.shape, matvec = Mv)
        
        x, info = cg(A_csr, b, M = M, rtol = rtol, maxiter = maxiter, x0 = x0)

        if info > 0:
            print(f"[警告][t={t}] Krylov法が収束しませんでした (info={info})")
        elif info < 0:
            print(f"[エラー][t={t}] Krylov法の入力が不正です (info={info})")

        # 写入与热启动
        T_all[t] = x.reshape((ni, nj, nk), order="F")
        x0 = x

        # 数値異常検出（DHCP温度場）
        is_valid, status_msg = check_temperature_field(T_all[t], timestep=t, dx=dx, dy=dy, dz=dz)
        if not is_valid:
            print(f"[DHCP警告][t={t}] 温度場異常: {status_msg}")
            # 重大な異常の場合は計算を停止する選択肢もある
            # 現在は警告のみで継続


    return T_all
    
'''
=== Adjoint problem solver  ===

coefficients(a*) for A whitch used csr_matrix (Compressed Sparse Row matrix: CSR) class
and right hand side (b) building for adjoint problem for all time step (Ax = b)
'''
@njit(parallel=True, fastmath=False)
def coeffs_and_rhs_building_Adjoint(lambda_initial, T_cal, Y_obs, rho, cp, k, dx, dy, dz, dz_b, dz_t, dt):
    ni, nj, nk = lambda_initial.shape
    N = ni * nj * nk
    
    a_w = np.zeros(N)
    a_e = np.zeros(N)
    a_s = np.zeros(N)
    a_n = np.zeros(N)
    a_b = np.zeros(N)
    a_t = np.zeros(N)
    a_p = np.zeros(N)
    
    b   = np.zeros(N)
    
    for p in prange(N):
        i = p % ni
        j = (p // ni) % nj
        k_ijk = p // (ni * nj)
        
        dz_k = dz[k_ijk]
        dz_t_k = dz_t[k_ijk]
        dz_b_k = dz_b[k_ijk]
        
        k_p = k[i, j, k_ijk]
        
        a_p_0 = rho * cp[i, j, k_ijk] * dx * dy * dz_k / dt
        
        a_w[p] = 0.0 if j == 0                 else (2 * k_p * k[i, j-1, k_ijk] / (k_p + k[i, j-1, k_ijk])) * dy * dz_k / dx
        a_e[p] = 0.0 if j == nj-1              else (2 * k_p * k[i, j+1, k_ijk] / (k_p + k[i, j+1, k_ijk])) * dy * dz_k / dx
        a_s[p] = 0.0 if i == 0                 else (2 * k_p * k[i-1, j, k_ijk] / (k_p + k[i-1, j, k_ijk])) * dx * dz_k / dy
        a_n[p] = 0.0 if i == ni-1              else (2 * k_p * k[i+1, j, k_ijk] / (k_p + k[i+1, j, k_ijk])) * dx * dz_k / dy
        a_b[p] = 0.0 if k_ijk == 0             else (2 * k_p * k[i, j, k_ijk-1] / (k_p + k[i, j, k_ijk-1])) * dx * dy / dz_b_k
        a_t[p] = 0.0 if k_ijk == nk-1          else (2 * k_p * k[i, j, k_ijk+1] / (k_p + k[i, j, k_ijk+1])) * dx * dy / dz_t_k
        
        a_p[p] = a_w[p] + a_e[p] + a_s[p] + a_n[p] + a_b[p] + a_t[p] + a_p_0
        
        rhs = a_p_0 * lambda_initial[i, j, k_ijk]
        
        if k_ijk == 0:
            rhs += 2 * (T_cal[i, j] - Y_obs[i, j]) * dx * dy
        b[p] = rhs
        
    return a_w, a_e, a_s, a_n, a_b, a_t, a_p, b

def assemble_A_Adjoint(ni, nj, nk, a_w, a_e, a_s, a_n, a_b, a_t, a_p):
    N = ni * nj * nk
    
    off_i = 1           # offsets for i direction (south & north)
    off_j = ni          # offsets for j direction (west & east)
    off_k = ni * nj     # offsets for k direction (bottom & top)

    D0   = a_p.copy()                 # len N
    D_im1 = -a_s[off_i: ]        # len N-1
    D_jm1 = -a_w[off_j: ]        # len N-ni
    D_km1 = -a_b[off_k: ]        # len N-ni*nj
    
    D_ip1 = -a_n[ :N-off_i]         # len N-1
    D_jp1 = -a_e[ :N-off_j]         # len N-ni
    D_kp1 = -a_t[ :N-off_k]         # len N-ni*nj

    A_csr = diags(
        diagonals=[D0, D_im1, D_jm1, D_km1, D_kp1, D_jp1, D_ip1],
        offsets=[0, -off_i, -off_j, -off_k, off_k, off_j, off_i],
        shape=(N, N), format="csr"
    )
    
    return A_csr


def multiple_time_step_solver_Adjoint(T_cal, Y_obs, nt, rho, cp_coeffs, k_coeffs,
                                       dx, dy, dz, dz_b, dz_t, dt, rtol, maxiter):
    '''
    nt: time step number for Temperature measurement (Y_obs)

    T_cal: 3D Temperature distributation at every time step based on DHCP solver
            T_cal.shape = (nt, ni, nj, nk)

    Y_obs: 2D Temperature distributation at every time step based on IR camera reading

    return: lambda_field.shape = (nt, ni, nj, nk)
    '''

    ni, nj, nk = T_cal[0].shape
    N = ni * nj * nk

    # 大規模問題でのメモリ監視（Adjoint開始時）
    if N > 100000:  # 約10万要素以上の場合
        current_memory, is_critical = monitor_memory_usage(f"Adjoint開始(N={N})",
                                                          warning_threshold_gb=6.0,
                                                          critical_threshold_gb=8.0)
        if is_critical:
            raise MemoryError("Adjoint: メモリ不足により計算を停止")

    lambda_field = np.empty_like(T_cal)
    lambda_field[-1] = 0

    lambda_initial = lambda_field[-1]

    x0 = lambda_initial.ravel(order = "F").copy()
    
    for t in range(nt-2, -1, -1):
        
        lambda_initial = lambda_field[t+1]
        
        cp, k = thermal_properties_calculator(T_cal[t], cp_coeffs, k_coeffs)
        
        a_w, a_e, a_s, a_n, a_b, a_t, a_p, b = coeffs_and_rhs_building_Adjoint(
            lambda_initial, T_cal[t][:,:,0], Y_obs[t], rho, cp, k, dx, dy, dz, dz_b, dz_t, dt)
        
        A_csr = assemble_A_Adjoint(ni, nj, nk, a_w, a_e, a_s, a_n, a_b, a_t, a_p)

        diag = A_csr.diagonal()
        inv_diag = np.where(diag != 0.0, 1.0/diag, 0.0)  # 防除零
        
        def Mv(z):
            return inv_diag * z
        
        M = LinearOperator(A_csr.shape, matvec = Mv)
        
        x, info = cg(A_csr, b, M = M, rtol = rtol, maxiter = maxiter, x0 = x0)


        if info > 0:
            print(f"[警告][t={t}] Krylov法が収束しませんでした (info={info})")
        elif info < 0:
            print(f"[エラー][t={t}] Krylov法の入力が不正です (info={info})")

        # 写入与热启动
        lambda_field[t] = x.reshape((ni, nj, nk), order="F")
        x0 = x

        # 数値異常検出（Adjoint随伴場）
        is_valid, status_msg = check_adjoint_field(lambda_field[t], timestep=t, dx=dx, dy=dy, dz=dz)
        if not is_valid:
            print(f"[Adjoint警告][t={t}] 随伴場異常: {status_msg}")

    return lambda_field

'''
=== CGM for one time window ===
Prediction of the surface heat flux by using the Conjugate gradient method: CGM
'''

def global_CGM_time(T_init, Y_obs, q_init, dx, dy, dz, dz_b, dz_t, dt, 
                        rho, cp_coeffs, k_coeffs, CGM_iteration = 20000
                        ):
    
    nt = Y_obs.shape[0]                             # Y_obs shape(nt, ni, nj) Observation Temperature array for whole time domain
    ni, nj, nk = T_init.shape                       # T_init shape(ni, nj, nk) Initial temperature distribution
    q = q_init.copy()                               # (nt-1, ni, nj) Initial surface heat flux guess
    
    J_hist = []                                     # J_list J saving for every iteration
    
    M = ni * nj
    sigma = 1.8                                                 # Measurement error assumption
    epsilon = M * (sigma ** 2) * (nt-1)                         # iteration stop criteration
    
    grad = np.zeros_like(q)                         # grad_J_q shape(nt-1, ni, nj) heat flux change gradient for upper surface 
    grad_last = np.zeros_like(q)                    # grad_J_q_last shape(nt-1, ni, nj) heat flux change gradient for upper surface at the last iteration
    
    bottom_idx, top_idx = 0, -1
    # eps safeguards divisions; adjust if the solver stalls
    eps = 1e-12
    dire_reset_every = 5
    
    p_n_last = np.zeros_like(q)
    
    # —— 平台检测参数 —— #
    P = 10                      # 近 P 次平均
    eta = 1e-4                  # 平均相对下降阈值（<0.01%）
    min_iter = 10               # 最小迭代数，防早停

    def _dot(a, b):
        return float(np.tensordot(a, b, axes = a.ndim))

    # CGMループ開始前のメモリ状況確認
    current_memory, is_critical = monitor_memory_usage("CGMループ開始",
                                                      warning_threshold_gb=6.0,
                                                      critical_threshold_gb=8.0)
    if is_critical:
        print("🚨 メモリ不足のため計算を開始できません")
        return q, T_init, []

    for it in range(CGM_iteration):
        t0 = time.time()

        # 定期的なメモリ監視（10反復ごと）
        if it % 10 == 0 or it < 5:  # 最初の5回は毎回、その後は10回ごと
            current_memory, is_critical = monitor_memory_usage(f"CGM反復{it}",
                                                              warning_threshold_gb=6.0,
                                                              critical_threshold_gb=8.0)
            if is_critical:
                print(f"🚨 メモリ不足により計算を停止します（反復{it}）")
                break

        # Step 1: direct problem for all time steps
        T_cal = multiple_time_step_solver_DHCP(
            T_init, q, nt, rho, cp_coeffs, k_coeffs,
            dx, dy, dz, dz_b, dz_t, dt,
            rtol = 1e-6, maxiter = 20000
            )
            
        # Step 2: stopping criterion check
        res_T = T_cal[1:, :, :, bottom_idx] - Y_obs[1:] # shape = (nt-1, ni, nj)
        delta_T = np.abs(res_T)
        J = float(np.tensordot(res_T, res_T, axes = res_T.ndim))
        J_hist.append(J)
        
        # ================== 统一停机判断（Discrepancy & Calculation Bottleneck） ================== #
        # Discrepancy（成功停机）
        if it >= min_iter and J < epsilon and delta_T.max() <= sigma:
            print(f"[停止] Discrepancy条件を満足：J={J:.4e} < {epsilon:.4e} かつ max|ΔT|={delta_T.max():.3e} ≤ σ={sigma}")
            break

        # 平台：近 P 次平均相对下降很小（进展到瓶颈）
        rel_drop_avg = None
        if len(J_hist) >= P + 1:
            drops = []
            for i in range(-P, 0):
                prev_i, cur_i = J_hist[i-1], J_hist[i]
                drops.append(max(0.0, (prev_i - cur_i) / (abs(prev_i) + eps)))
            rel_drop_avg = sum(drops) / P

        if it >= min_iter and rel_drop_avg is not None and rel_drop_avg < eta:
            print(f"[停止] プラトー：rel_drop_avg={rel_drop_avg:.3e} < eta={eta:.1e}（直近{P}ステップの平均進展が微小）")
            break
        # ================== 统一停机判断结束 ================== #
        
        # Step 3: adjoint problem solution
        lambda_field =  multiple_time_step_solver_Adjoint(
            T_cal, Y_obs, nt, rho, cp_coeffs, k_coeffs,
            dx, dy, dz, dz_b, dz_t, dt,
            rtol = 1e-8, maxiter = 20000
            )

        # CGMレベルでの包括的異常検出（随伴場）
        is_lambda_valid, lambda_status = check_adjoint_field(lambda_field, iteration=it, dx=dx, dy=dy, dz=dz)
        if not is_lambda_valid:
            print(f"[CGM警告][反復{it}] 随伴場全体異常: {lambda_status}")
            # 従来の簡易チェックも保持（互換性のため）
            if not np.isfinite(lambda_field).all():
                print(f"[CGM重大][反復{it}] lambda_fieldでNaN/Infが検出されました - 計算停止を検討")
            
        # Step 4: gradient calculation for all time steps
        for n in range(nt - 1):
            grad[n] = lambda_field[n][:, :, top_idx]                 # gradient distributation field of the top surface (nt, ni, nj)

        # 勾配場の異常検出
        is_grad_valid, grad_status = check_flux_field(grad, iteration=it, dx=dx, dy=dy)
        if not is_grad_valid:
            print(f"[CGM警告][反復{it}] 勾配場異常: {grad_status}")

        # Step 5: conjugate gradient direction calculation
        if it == 0 or _dot(grad, p_n_last) <= 0 or it % dire_reset_every == 0:
            p_n = grad.copy()
            gamma = 0    
        else:
            y = grad - grad_last
            denom = _dot(grad_last,grad_last) + eps
            gamma = max(0, _dot(grad, y) / denom)
            p_n_candidate = grad + gamma * p_n_last
            
            if _dot(grad, p_n_candidate) > 0:
                p_n = p_n_candidate
                
            else:
                p_n = grad.copy()

        p_n_last = p_n.copy()
        
        # Step 6: set delta_q = p_n on top surface，solve the sensitivity problem
        dT_init = np.zeros_like(T_init)
        dT = multiple_time_step_solver_DHCP(
                dT_init, p_n, nt, rho, cp_coeffs, k_coeffs,
                dx, dy, dz, dz_b, dz_t, dt,
                rtol = 1e-8, maxiter = 20000
                )

        # 感度場dTの異常検出
        is_dT_valid, dT_status = check_temperature_field(dT, dx=dx, dy=dy, dz=dz)
        if not is_dT_valid:
            print(f"[CGM警告][反復{it}] 感度場dT異常: {dT_status}")

        # Step 7: search step size
        Sp = dT[1:, :, :, bottom_idx]
        assert res_T.shape == Sp.shape, (res_T.shape, Sp.shape)
        numerator   = float(np.tensordot(res_T, Sp, axes=res_T.ndim))
        denominator = float(np.tensordot(Sp,  Sp,  axes=Sp.ndim))
        
        beta = numerator / (denominator + eps)
        
        # step size limitation
        beta_max = 1e8

        if it == 0 and abs(beta) > beta_max:
            print(f"  [WARN] beta clipped: {beta:.2e} => {np.sign(beta)*beta_max:.2e}")
            beta = np.clip(beta, -beta_max, beta_max)
        
        # print_interval = 10
        # if it % print_interval == 0 or it == 0 or it == CGM_iteration - 1:
            
        ''' relative desent rate '''    
        rel_drop = None
        if len(J_hist) >= 2:
            rel_drop = abs(J_hist[-1] - J_hist[-2]) / (J_hist[-2])
        
        wall_s = time.time() - t0
        print(f"@ ___ Iter {it:3d} ___ @ wall_s = {wall_s:.3f}s")
        print(f"J = {J:.5e}, beta = {beta:.4e}, rel_drop = {None if rel_drop is None else f'{rel_drop:.3e}'}")
        print(f"|T - Y|: max={delta_T.max():.3e}, min={delta_T.min():.3e}, mean={delta_T.mean():.3e}")
        print(f"grad: min={grad.min():.4e}, max={grad.max():.4e}, mean={grad.mean():.4e}")
        print(f"dT:   min={dT[1:].min():.4e}, max={dT[1:].max():.4e}, mean={dT[1:].mean():.4e}")
        print(f"q:    min={q.min():.4e}, max={q.max():.4e}, mean={q.mean():.4e}") 
        print(f"denominator at iter {it}: {denominator:.4e}")
   
        # 更新q
        q = q - beta * p_n

        # 熱流束qの異常検出
        is_q_valid, q_status = check_flux_field(q, iteration=it, dx=dx, dy=dy)
        if not is_q_valid:
            print(f"[CGM警告][反復{it}] 熱流束q異常: {q_status}")

        grad_last = grad.copy()
        
    return q, T_cal[-1], J_hist


def sliding_window_CGM_q_saving(
    Y_obs, T0, dx, dy, dz, dz_b, dz_t, dt, rho, cp_coeffs, k_coeffs,
    window_size, overlap, q_init_value, filename, CGM_iteration=20000
):
    nt = Y_obs.shape[0]
    T_init = T0.copy()
    ni, nj, nk = T_init.shape

    start_idx = 0
    q_total = []
    prev_q_win = None

    safety_counter = 0
    safety_limit = nt * 5  # 经验值

    while start_idx < nt - 1:
        safety_counter += 1
        if safety_counter > safety_limit:
            print("Safety break: too many iterations, check overlap/window settings.")
            break

        # 当前可用窗长
        max_L = min(window_size, (nt - 1) - start_idx)
        end_idx = start_idx + max_L
        Y_obs_win = Y_obs[start_idx: end_idx + 1, :, :]

        # 该窗的初始热流
        if prev_q_win is None:
            q_init_win = np.full((max_L, ni, nj), q_init_value, dtype=float)
        else:
            q_init_win = np.empty((max_L, ni, nj), dtype=float)
            L_overlap = min(overlap, max_L, prev_q_win.shape[0])
            if L_overlap > 0:
                q_init_win[:L_overlap] = prev_q_win[-L_overlap:]
            if L_overlap < max_L:
                edge = prev_q_win[-1]
                q_init_win[L_overlap:] = edge

        start_time_one_window = time.time()
        q_win, T_win_last, J_hist = global_CGM_time(
            T_init, Y_obs_win, q_init_win, dx, dy, dz, dz_b, dz_t, dt,
            rho, cp_coeffs, k_coeffs, CGM_iteration=CGM_iteration
        )
        end_time_one_window = time.time()

        prev_q_win = q_win.copy()

        # 拼接 q（对重叠部分做平均）
        if len(q_total) == 0:
            q_total.append(q_win)
        else:
            overlap_steps = min(overlap, q_win.shape[0], q_total[-1].shape[0])
            if overlap_steps > 0:
                q_total[-1][-overlap_steps:] = 0.5 * q_total[-1][-overlap_steps:] + q_win[:overlap_steps]
                q_total.append(q_win[overlap_steps:])
            else:
                q_total.append(q_win)

        T_init = T_win_last.copy() if T_win_last.ndim == 3 else T_win_last[-1].copy()

        print(f"ウィンドウ {start_idx*dt} - {end_idx*dt} 完了。J = {J_hist[-1]:.3f}, "
              f"計算時間 = {end_time_one_window - start_time_one_window:.2f}s")

        step = max(1, max_L - overlap)
        start_idx += step

    # 拼接为全局 q，并裁剪到 nt-1
    q_global = np.concatenate(q_total, axis=0)[:nt-1]
    np.save(filename, q_global)
    print(f"熱流束qを保存しました: {filename}, shape={q_global.shape}")
    return q_global


# %%

'''
# === Main Execution  for single calculation window === #

1. Read npy files whitch was processed based on the matlab format files from the IR camera
2. Extract the down side temperature distribution as the initial temperature distribution
3. selection the heat flux calculation domain
4. set a initial heat flux guess
5. surface heat flux calculation for a single calculation window

=== 
'''       
def main():
    start_All = time.time()

    # 初期メモリ状況の確認
    print("=" * 80)
    print("IHCP-CGM計算開始 - メモリ監視システム有効")
    print("=" * 80)
    monitor_memory_usage("計算開始前", warning_threshold_gb=6.0, critical_threshold_gb=8.0)

    # 大容量データファイルの安全読み込み
    data_filepath = BASE_DIR / "T_measure_700um_1ms.npy"
    try:
        T_measure_K = safe_load_large_data(data_filepath, max_size_gb=2.0, memory_check=True)
    except (MemoryError, ValueError, FileNotFoundError) as e:
        print(f"❌ データ読み込み失敗: {e}")
        print("推奨対応:")
        print("  1. より小さなデータサイズでのテスト")
        print("  2. メモリを増設")
        print("  3. データの分割読み込み")
        return

    dt = 0.001

    T_measure_init_K = T_measure_K[0, :, :]
    T0 = np.repeat(T_measure_init_K[:, :, np.newaxis], nz, axis=2).astype(np.float64)  # shape: (ny, nx, nz)

    Y_obs = T_measure_K[:500, :, :]
    nt, ni, nj = Y_obs.shape
    nk = T0.shape[2]
    q_init = np.zeros((nt - 1, ni, nj))

    # 拡散数による数値安定性チェック
    # SUS304の熱物性値の範囲から最大・最小値を取得
    k_max = 34.00      # 最大熱伝導率 [W/(m·K)] at 1600°C
    rho_min = 7264.0   # 最小密度 [kg/m³] at 1600°C
    cp_min = 510.37    # 最小比熱 [J/(kg·K)] at 300°C
    dz_min = dz.min()  # 最小格子サイズ [m]

    print("数値安定性チェック開始...")
    max_diff_num, diff_nums = check_diffusion_stability(
        dx, dy, dz_min, dt, k_max, rho_min, cp_min
    )
    print("数値安定性チェック完了。")
    print()

    # CGM計算開始前のメモリ確認
    monitor_memory_usage("CGM計算開始前", warning_threshold_gb=6.0, critical_threshold_gb=8.0)

    global_CGM_time(
        T0, Y_obs, q_init, dx, dy, dz, dz_b, dz_t, dt, rho, cp_coeffs, k_coeffs
    )

    end_All = time.time()
    print(f"Time for the whole calculation process:{end_All - start_All}")

'''绘制下表面温度对照图检查是否正确'''

if __name__ == "__main__":
    main()
