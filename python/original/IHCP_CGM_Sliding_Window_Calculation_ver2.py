# -*- coding: utf-8 -*-
"""
Created on Tue Aug 19 20:18:01 2025

@author: SHI ZHENGQI

Final Version of Inverse Heat Conduction Problem by using The Conjugate Gradient Mtehod: CGM

-1- Read Matlab Files whitch were generated by the IR Camera in matlab format
-2- Poly Fit the Thermal Properties (heat conductivity & specific heat)
-3- Direct Solver for heat transfer equation
-4- Adjoint Solver for CGM
-5- surface heat flux inverse calculation for a single calculation window
-6- surface heat flux inverse calculation for the whole time domain 

"""

import re
import os
import time
from pathlib import Path
from math import sin, radians

import numpy as np
import pandas as pd

from numba import njit, prange
from scipy.io import loadmat

from scipy.sparse.linalg import LinearOperator,cg
from scipy.sparse import diags
import warnings
import psutil
import gc

BASE_DIR = Path(__file__).resolve().parent

# === Reading and Poly-Fitting Thermal Properties for SUS304 === #
Thermal_properties_file_path = BASE_DIR / "metal_thermal_properties.csv"
# Thermal_properties_file_path = "D:/HT_Calculation_Python\\thermal_properties_SUS304\\metal_thermal_properties.csv"
# Thermal_properties_file_path = "C:/HT_Calculation_Python\\thermal_properties_SUS304\\metal_thermal_properties.csv"
sus304_data = pd.read_csv(Thermal_properties_file_path)

sus304_temp = sus304_data['Temperature/K'].values
sus304_rho = sus304_data['Density'].values
sus304_cp = sus304_data['Specific_Heat'].values
sus304_k = sus304_data['Thermal_Conductivity'].values

# Getting the 3-rd Poly Fiiting Factors for Density/Specific Heat/Thermal Conductivity
rho_coeffs = np.polyfit(sus304_temp, sus304_rho, 3)
cp_coeffs = np.polyfit(sus304_temp, sus304_cp, 3)
k_coeffs  = np.polyfit(sus304_temp, sus304_k,  3)
# Result = [a,b,c,d] for y = ax^3 + bx^2 + cx + d

# Poly-fit Result Calculation Unit / Return result = ax^3 + bx^2 + cx + d
@njit
def polyval_numba(coeffs, x):
    result = 0.0
    for i in range(len(coeffs)):
        result += coeffs[i] * x ** (len(coeffs) - i - 1)
    return result

@njit(parallel = True)
def thermal_properties_calculator(Temperature, cp_coeffs, k_coeffs):
    
    ni, nj, nk = Temperature.shape
    cp = np.empty((ni, nj, nk))
    k = np.empty((ni, nj, nk))

    for i in prange(ni):
        for j in range(nj):
            for k_ijk in range(nk):
                
                T_current = Temperature[i, j, k_ijk]
                cp[i, j, k_ijk] = polyval_numba(cp_coeffs, T_current)
                k[i, j, k_ijk] = polyval_numba(k_coeffs, T_current)
                
    return cp, k

rho = polyval_numba(rho_coeffs, 225 + 273.15)

# ==========================================================================
# === æ•°å€¤ç•°å¸¸æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ  (Numerical Anomaly Detection System) ===
# ==========================================================================

@njit
def check_field_finite(field):
    """
    ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æœ‰é™æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆé«˜é€Ÿç‰ˆï¼‰

    Parameters:
    -----------
    field : numpy.ndarray
        æ¤œæŸ»å¯¾è±¡ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰

    Returns:
    --------
    bool : ã™ã¹ã¦æœ‰é™ã®å ´åˆTrue
    """
    flat_field = field.ravel()
    for i in range(flat_field.size):
        if not np.isfinite(flat_field[i]):
            return False
    return True

@njit
def check_temperature_range(T, min_temp=150.0, max_temp=3000.0):
    """
    æ¸©åº¦å ´ã®ç‰©ç†çš„ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆé«˜é€Ÿç‰ˆï¼‰

    Parameters:
    -----------
    T : numpy.ndarray
        æ¸©åº¦å ´ [K]
    min_temp : float
        æœ€å°è¨±å®¹æ¸©åº¦ [K]
    max_temp : float
        æœ€å¤§è¨±å®¹æ¸©åº¦ [K]

    Returns:
    --------
    bool : ç¯„å›²å†…ã®å ´åˆTrue
    float : æœ€å°å€¤
    float : æœ€å¤§å€¤
    """
    flat_T = T.ravel()
    min_val = flat_T[0]
    max_val = flat_T[0]

    for i in range(flat_T.size):
        val = flat_T[i]
        if val < min_val:
            min_val = val
        if val > max_val:
            max_val = val

    is_valid = (min_val >= min_temp) and (max_val <= max_temp)
    return is_valid, min_val, max_val

@njit
def check_flux_range(q, max_abs_flux=1e7):
    """
    ç†±æµæŸã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆé«˜é€Ÿç‰ˆï¼‰

    Parameters:
    -----------
    q : numpy.ndarray
        ç†±æµæŸ [W/mÂ²]
    max_abs_flux : float
        æœ€å¤§è¨±å®¹çµ¶å¯¾å€¤ [W/mÂ²]

    Returns:
    --------
    bool : ç¯„å›²å†…ã®å ´åˆTrue
    float : æœ€å°å€¤
    float : æœ€å¤§å€¤
    """
    flat_q = q.ravel()
    min_val = flat_q[0]
    max_val = flat_q[0]

    for i in range(flat_q.size):
        val = flat_q[i]
        if val < min_val:
            min_val = val
        if val > max_val:
            max_val = val

    max_abs = max(abs(min_val), abs(max_val))
    is_valid = max_abs <= max_abs_flux
    return is_valid, min_val, max_val

@njit
def check_gradient_magnitude(field, dx, dy, dz, max_grad_temp=5000.0, max_grad_flux=1e8):
    """
    ç©ºé–“å‹¾é…ã®å¤§ãã•ãƒã‚§ãƒƒã‚¯ï¼ˆé«˜é€Ÿç‰ˆï¼‰

    Parameters:
    -----------
    field : numpy.ndarray
        ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆæ¸©åº¦ã¾ãŸã¯ç†±æµæŸï¼‰
    dx, dy : float
        x, yæ–¹å‘ã®æ ¼å­é–“éš” [m]
    dz : numpy.ndarray
        zæ–¹å‘ã®æ ¼å­é–“éš”é…åˆ— [m]
    max_grad_temp : float
        æ¸©åº¦å‹¾é…ã®æœ€å¤§è¨±å®¹å€¤ [K/m]
    max_grad_flux : float
        ç†±æµæŸå‹¾é…ã®æœ€å¤§è¨±å®¹å€¤ [W/mÂ³]

    Returns:
    --------
    bool : è¨±å®¹ç¯„å›²å†…ã®å ´åˆTrue
    float : æœ€å¤§å‹¾é…å€¤
    """
    if field.ndim == 2:
        # 2æ¬¡å…ƒãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆè¡¨é¢ç†±æµæŸï¼‰
        ni, nj = field.shape
        max_grad = 0.0

        # xæ–¹å‘å‹¾é…
        for i in range(ni-1):
            for j in range(nj):
                grad = abs(field[i+1, j] - field[i, j]) / dy  # æ³¨ï¼šiæ–¹å‘ãŒyç‰©ç†æ–¹å‘
                if grad > max_grad:
                    max_grad = grad

        # yæ–¹å‘å‹¾é…
        for i in range(ni):
            for j in range(nj-1):
                grad = abs(field[i, j+1] - field[i, j]) / dx  # æ³¨ï¼šjæ–¹å‘ãŒxç‰©ç†æ–¹å‘
                if grad > max_grad:
                    max_grad = grad

        is_valid = max_grad <= max_grad_flux

    elif field.ndim == 3:
        # 3æ¬¡å…ƒãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆæ¸©åº¦å ´ï¼‰
        ni, nj, nk = field.shape
        max_grad = 0.0

        # xæ–¹å‘å‹¾é…
        for i in range(ni-1):
            for j in range(nj):
                for k in range(nk):
                    grad = abs(field[i+1, j, k] - field[i, j, k]) / dy
                    if grad > max_grad:
                        max_grad = grad

        # yæ–¹å‘å‹¾é…
        for i in range(ni):
            for j in range(nj-1):
                for k in range(nk):
                    grad = abs(field[i, j+1, k] - field[i, j, k]) / dx
                    if grad > max_grad:
                        max_grad = grad

        # zæ–¹å‘å‹¾é…
        for i in range(ni):
            for j in range(nj):
                for k in range(nk-1):
                    grad = abs(field[i, j, k+1] - field[i, j, k]) / dz[k]
                    if grad > max_grad:
                        max_grad = grad

        is_valid = max_grad <= max_grad_temp
    else:
        # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„æ¬¡å…ƒ
        return False, 0.0

    return is_valid, max_grad

def detect_numerical_anomalies(field, field_name, iteration=None, timestep=None,
                                temperature_range=(150.0, 3000.0), flux_range=(-1e7, 1e7),
                                dx=0.12e-3, dy=0.12e-3*0.866, dz=None):
    """
    æ•°å€¤è¨ˆç®—ã«ãŠã‘ã‚‹ç•°å¸¸å€¤ã‚’åŒ…æ‹¬çš„ã«æ¤œå‡º

    Parameters:
    -----------
    field : numpy.ndarray
        æ¤œæŸ»å¯¾è±¡ã®ç‰©ç†å ´
    field_name : str
        ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åï¼ˆæ¸©åº¦å ´ã€ç†±æµæŸã€å‹¾é…ç­‰ï¼‰
    iteration : int, optional
        CGMåå¾©å›æ•°
    timestep : int, optional
        æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—
    temperature_range : tuple
        æ¸©åº¦ã®ç‰©ç†çš„ç¯„å›² [K]
    flux_range : tuple
        ç†±æµæŸã®ç‰©ç†çš„ç¯„å›² [W/mÂ²]
    dx, dy : float
        x, yæ–¹å‘ã®æ ¼å­é–“éš” [m]
    dz : numpy.ndarray, optional
        zæ–¹å‘ã®æ ¼å­é–“éš”é…åˆ— [m]

    Returns:
    --------
    bool : ç•°å¸¸ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆTrue
    list : æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸ã®ãƒªã‚¹ãƒˆ
    """
    anomalies = []

    # 1. NaN/Infå€¤ãƒã‚§ãƒƒã‚¯
    if not check_field_finite(field):
        anomalies.append(f"NaN/Infå€¤æ¤œå‡º")

    # 2. ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç¨®é¡åˆ¥ã®è©³ç´°ãƒã‚§ãƒƒã‚¯
    if "æ¸©åº¦" in field_name or "Temperature" in field_name or "T_" in field_name:
        # æ¸©åº¦å ´ã®æ¤œæŸ»
        is_valid, min_val, max_val = check_temperature_range(field, temperature_range[0], temperature_range[1])
        if not is_valid:
            if min_val < temperature_range[0]:
                anomalies.append(f"ç•°å¸¸ä½æ¸©æ¤œå‡º: min={min_val:.1f}K < {temperature_range[0]}K")
            if max_val > temperature_range[1]:
                anomalies.append(f"ç•°å¸¸é«˜æ¸©æ¤œå‡º: max={max_val:.1f}K > {temperature_range[1]}K")

        # æ¸©åº¦å‹¾é…ãƒã‚§ãƒƒã‚¯
        if dz is not None:
            is_grad_valid, max_grad = check_gradient_magnitude(field, dx, dy, dz, max_grad_temp=5000.0)
            if not is_grad_valid:
                anomalies.append(f"ç•°å¸¸ãªæ¸©åº¦å‹¾é…: {max_grad:.1f}K/m > 5000K/m")

    elif "ç†±æµæŸ" in field_name or "flux" in field_name or "q_" in field_name or field_name == "q":
        # ç†±æµæŸå ´ã®æ¤œæŸ»
        is_valid, min_val, max_val = check_flux_range(field, max(abs(flux_range[0]), abs(flux_range[1])))
        if not is_valid:
            max_abs = max(abs(min_val), abs(max_val))
            anomalies.append(f"ç•°å¸¸ãªç†±æµæŸ: max_abs={max_abs:.2e}W/mÂ² > {max(abs(flux_range[0]), abs(flux_range[1])):.2e}W/mÂ²")

        # ç†±æµæŸå‹¾é…ãƒã‚§ãƒƒã‚¯ï¼ˆ2æ¬¡å…ƒã®å ´åˆï¼‰
        if field.ndim == 2:
            is_grad_valid, max_grad = check_gradient_magnitude(field, dx, dy, np.array([0.0]), max_grad_flux=1e8)
            if not is_grad_valid:
                anomalies.append(f"ç•°å¸¸ãªç†±æµæŸå‹¾é…: {max_grad:.2e}W/mÂ³ > 1e8W/mÂ³")

    elif "lambda" in field_name or "å‹¾é…" in field_name or "gradient" in field_name:
        # éšä¼´å ´ãƒ»å‹¾é…å ´ã®æ¤œæŸ»
        is_valid, min_val, max_val = check_flux_range(field, 1e10)  # ã‚ˆã‚Šå¤§ããªè¨±å®¹ç¯„å›²
        if not is_valid:
            max_abs = max(abs(min_val), abs(max_val))
            anomalies.append(f"ç•°å¸¸ãªéšä¼´å ´/å‹¾é…: max_abs={max_abs:.2e} > 1e10")

    # 3. ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼æ¤œæŸ»
    float64_max = np.finfo(np.float64).max
    field_flat = field.ravel()
    max_abs_val = np.max(np.abs(field_flat))
    if max_abs_val > float64_max * 0.1:  # float64æœ€å¤§å€¤ã®10%ã‚’è¶…ãˆã‚‹å ´åˆ
        anomalies.append(f"æ•°å€¤ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã®å±é™º: max_abs={max_abs_val:.2e} > {float64_max*0.1:.2e}")

    return len(anomalies) > 0, anomalies

def handle_numerical_anomaly(field_name, anomalies, iteration=None, timestep=None,
                             suggested_action="è¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„"):
    """
    æ•°å€¤ç•°å¸¸ã¸ã®å¯¾å¿œã‚¢ã‚¯ã‚·ãƒ§ãƒ³

    Parameters:
    -----------
    field_name : str
        ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å
    anomalies : list
        æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸ã®ãƒªã‚¹ãƒˆ
    iteration : int, optional
        CGMåå¾©å›æ•°
    timestep : int, optional
        æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—
    suggested_action : str
        æ¨å¥¨å¯¾å¿œç­–
    """
    timestamp = ""
    if iteration is not None:
        timestamp += f"[CGMåå¾©{iteration}]"
    if timestep is not None:
        timestamp += f"[æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—{timestep}]"

    print("\n" + "="*80)
    print(f"ğŸš¨ æ•°å€¤ç•°å¸¸æ¤œå‡ºã‚¢ãƒ©ãƒ¼ãƒˆ: {field_name} {timestamp}")
    print("="*80)

    for i, anomaly in enumerate(anomalies, 1):
        print(f"{i:2d}. {anomaly}")

    print("-"*80)
    print(f"ğŸ“‹ æ¨å¥¨å¯¾å¿œç­–: {suggested_action}")
    print("="*80)

    # é‡å¤§ãªç•°å¸¸ã®å ´åˆã¯è¿½åŠ è­¦å‘Š
    critical_keywords = ["NaN", "Inf", "ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼"]
    if any(keyword in anomaly for anomaly in anomalies for keyword in critical_keywords):
        print("âš ï¸  é‡å¤§: è¨ˆç®—ã®ç¶™ç¶šã¯å±é™ºã§ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¦‹ç›´ã—ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚")
        print("="*80)

def check_temperature_field(T, timestep=None, dx=0.12e-3, dy=0.12e-3*0.866, dz=None):
    """
    æ¸©åº¦å ´ã®åŒ…æ‹¬çš„ãƒã‚§ãƒƒã‚¯

    Parameters:
    -----------
    T : numpy.ndarray
        æ¸©åº¦å ´ [K]
    timestep : int, optional
        æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—
    dx, dy : float
        æ ¼å­é–“éš” [m]
    dz : numpy.ndarray, optional
        zæ–¹å‘æ ¼å­é–“éš”é…åˆ— [m]

    Returns:
    --------
    bool : ç•°å¸¸æ¤œå‡ºæ™‚False
    str : çŠ¶æ…‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    has_anomaly, anomalies = detect_numerical_anomalies(
        T, "æ¸©åº¦å ´", timestep=timestep, dx=dx, dy=dy, dz=dz
    )

    if has_anomaly:
        handle_numerical_anomaly("æ¸©åº¦å ´", anomalies, timestep=timestep,
                                suggested_action="æ™‚é–“åˆ»ã¿ã®ç¸®å°ã¾ãŸã¯ãƒ¡ãƒƒã‚·ãƒ¥èª¿æ•´ã‚’æ¤œè¨")
        return False, f"ç•°å¸¸æ¤œå‡º: {len(anomalies)}ä»¶"

    return True, "æ­£å¸¸"

def check_flux_field(q, iteration=None, timestep=None, dx=0.12e-3, dy=0.12e-3*0.866):
    """
    ç†±æµæŸå ´ã®åŒ…æ‹¬çš„ãƒã‚§ãƒƒã‚¯

    Parameters:
    -----------
    q : numpy.ndarray
        ç†±æµæŸå ´ [W/mÂ²]
    iteration : int, optional
        CGMåå¾©å›æ•°
    timestep : int, optional
        æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—
    dx, dy : float
        æ ¼å­é–“éš” [m]

    Returns:
    --------
    bool : ç•°å¸¸æ¤œå‡ºæ™‚False
    str : çŠ¶æ…‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    has_anomaly, anomalies = detect_numerical_anomalies(
        q, "ç†±æµæŸ", iteration=iteration, timestep=timestep, dx=dx, dy=dy
    )

    if has_anomaly:
        handle_numerical_anomaly("ç†±æµæŸ", anomalies, iteration=iteration, timestep=timestep,
                                suggested_action="CGMã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºã®èª¿æ•´ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¦‹ç›´ã—")
        return False, f"ç•°å¸¸æ¤œå‡º: {len(anomalies)}ä»¶"

    return True, "æ­£å¸¸"

def check_adjoint_field(lambda_field, iteration=None, timestep=None, dx=0.12e-3, dy=0.12e-3*0.866, dz=None):
    """
    éšä¼´å ´ã®åŒ…æ‹¬çš„ãƒã‚§ãƒƒã‚¯

    Parameters:
    -----------
    lambda_field : numpy.ndarray
        éšä¼´å ´
    iteration : int, optional
        CGMåå¾©å›æ•°
    timestep : int, optional
        æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—
    dx, dy : float
        æ ¼å­é–“éš” [m]
    dz : numpy.ndarray, optional
        zæ–¹å‘æ ¼å­é–“éš”é…åˆ— [m]

    Returns:
    --------
    bool : ç•°å¸¸æ¤œå‡ºæ™‚False
    str : çŠ¶æ…‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    has_anomaly, anomalies = detect_numerical_anomalies(
        lambda_field, "éšä¼´å ´lambda", iteration=iteration, timestep=timestep, dx=dx, dy=dy, dz=dz
    )

    if has_anomaly:
        handle_numerical_anomaly("éšä¼´å ´", anomalies, iteration=iteration, timestep=timestep,
                                suggested_action="CGMåæŸæ¡ä»¶ã®ç·©å’Œã¾ãŸã¯åå¾©å›æ•°ã®åˆ¶é™")
        return False, f"ç•°å¸¸æ¤œå‡º: {len(anomalies)}ä»¶"

    return True, "æ­£å¸¸"

def handle_critical_anomaly(field_name, iteration=None, timestep=None, emergency_stop=True):
    """
    é‡å¤§ãªæ•°å€¤ç•°å¸¸ã¸ã®ç·Šæ€¥å¯¾å¿œ

    Parameters:
    -----------
    field_name : str
        ç•°å¸¸ãŒæ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å
    iteration : int, optional
        CGMåå¾©å›æ•°
    timestep : int, optional
        æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—
    emergency_stop : bool
        ç·Šæ€¥åœæ­¢ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã©ã†ã‹

    Returns:
    --------
    bool : è¨ˆç®—ã‚’åœæ­¢ã™ã¹ãã‹ã©ã†ã‹
    """
    timestamp = ""
    if iteration is not None:
        timestamp += f"[CGMåå¾©{iteration}]"
    if timestep is not None:
        timestamp += f"[æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—{timestep}]"

    print("\n" + "="*90)
    print(f"ğŸ”´ é‡å¤§ç•°å¸¸æ¤œå‡º - ç·Šæ€¥åœæ­¢ãƒ¢ãƒ¼ãƒ‰ {timestamp}")
    print("="*90)
    print(f"ç•°å¸¸ç®‡æ‰€: {field_name}")
    print(f"æ¤œå‡ºæ™‚åˆ»: {timestamp}")
    print("-"*90)
    print("é‡å¤§ç•°å¸¸ã®ç¨®é¡:")
    print("  â€¢ NaN/Infå€¤ã®æ¤œå‡º")
    print("  â€¢ æ•°å€¤ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼")
    print("  â€¢ ç‰©ç†çš„ã«ä¸å¯èƒ½ãªå€¤")
    print("-"*90)
    print("ç·Šæ€¥å¯¾å¿œç­–:")
    print("  1. è¨ˆç®—ã®å³åº§åœæ­¢")
    print("  2. ç¾åœ¨ã®çµæœã®ä¿å­˜")
    print("  3. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¦‹ç›´ã—")
    print("  4. ã‚ˆã‚Šå³ã—ã„å®‰å®šæ€§æ¡ä»¶ã§ã®å†é–‹")
    print("="*90)

    if emergency_stop:
        print("ğŸš¨ ç·Šæ€¥åœæ­¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        return True
    else:
        print("âš ï¸  è­¦å‘Šã®ã¿ã€‚è¨ˆç®—ã‚’ç¶™ç¶šã—ã¾ã™ã€‚")
        return False

def enhanced_anomaly_response(field, field_name, anomalies, iteration=None, timestep=None,
                              auto_stop_critical=True):
    """
    æ‹¡å¼µã•ã‚ŒãŸç•°å¸¸å¯¾å¿œã‚·ã‚¹ãƒ†ãƒ 

    Parameters:
    -----------
    field : numpy.ndarray
        ç•°å¸¸ãŒæ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    field_name : str
        ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å
    anomalies : list
        æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸ã®ãƒªã‚¹ãƒˆ
    iteration : int, optional
        CGMåå¾©å›æ•°
    timestep : int, optional
        æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—
    auto_stop_critical : bool
        é‡å¤§ç•°å¸¸æ™‚ã®è‡ªå‹•åœæ­¢ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹

    Returns:
    --------
    bool : è¨ˆç®—åœæ­¢ãŒå¿…è¦ã‹ã©ã†ã‹
    dict : è¨ºæ–­æƒ…å ±
    """
    # é‡å¤§ç•°å¸¸ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    critical_keywords = ["NaN", "Inf", "ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼"]

    # é‡å¤§åº¦ã®åˆ†é¡
    has_critical = any(keyword in anomaly for anomaly in anomalies for keyword in critical_keywords)
    has_physical_violation = any("ç•°å¸¸ä½æ¸©" in anomaly or "ç•°å¸¸é«˜æ¸©" in anomaly or "ç‰©ç†çš„" in anomaly for anomaly in anomalies)
    has_extreme_gradient = any("å‹¾é…" in anomaly for anomaly in anomalies)

    diagnosis = {
        "severity": "normal",
        "anomaly_count": len(anomalies),
        "has_critical": has_critical,
        "has_physical_violation": has_physical_violation,
        "has_extreme_gradient": has_extreme_gradient,
        "field_stats": {
            "min": float(np.min(field)),
            "max": float(np.max(field)),
            "mean": float(np.mean(field)),
            "std": float(np.std(field))
        },
        "recommendations": []
    }

    # é‡å¤§åº¦ã®åˆ¤å®šã¨å¯¾å¿œ
    if has_critical:
        diagnosis["severity"] = "critical"
        diagnosis["recommendations"].extend([
            "å³åº§ã«è¨ˆç®—ã‚’åœæ­¢ã—ã¦ãã ã•ã„",
            "æ•°å€¤ã‚¹ã‚­ãƒ¼ãƒ ã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™",
            "æ™‚é–“åˆ»ã¿ã‚’å¤§å¹…ã«ç¸®å°ã—ã¦ãã ã•ã„"
        ])

        if auto_stop_critical:
            should_stop = handle_critical_anomaly(field_name, iteration, timestep, emergency_stop=True)
            diagnosis["auto_stopped"] = should_stop
            return should_stop, diagnosis

    elif has_physical_violation:
        diagnosis["severity"] = "severe"
        diagnosis["recommendations"].extend([
            "ç‰©ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¦‹ç›´ã—ã‚’æ¤œè¨",
            "å¢ƒç•Œæ¡ä»¶ã®ç¢ºèª",
            "ææ–™ç‰©æ€§å€¤ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯"
        ])

    elif has_extreme_gradient:
        diagnosis["severity"] = "moderate"
        diagnosis["recommendations"].extend([
            "ãƒ¡ãƒƒã‚·ãƒ¥ã®ç´°åˆ†åŒ–ã‚’æ¤œè¨",
            "ç©ºé–“é›¢æ•£åŒ–ç²¾åº¦ã®å‘ä¸Š",
            "å‹¾é…ãƒªãƒŸãƒƒã‚¿ãƒ¼ã®å°å…¥"
        ])

    # æ¨™æº–çš„ãªç•°å¸¸å‡¦ç†
    handle_numerical_anomaly(field_name, anomalies, iteration, timestep)

    diagnosis["auto_stopped"] = False
    return False, diagnosis

# ==========================================================================
# === ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  (Memory Usage Monitoring System) ===
# ==========================================================================

def get_memory_info():
    """
    ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªæƒ…å ±ã®å–å¾—

    Returns:
    --------
    dict : ãƒ¡ãƒ¢ãƒªæƒ…å ±è¾æ›¸
        'rss_gb': å®Ÿãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ [GB]
        'vms_gb': ä»®æƒ³ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ [GB]
        'available_gb': åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª [GB]
        'total_gb': ç·ãƒ¡ãƒ¢ãƒªå®¹é‡ [GB]
        'percent': ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ [%]
    """
    try:
        process = psutil.Process()
        memory_info = process.memory_info()
        system_memory = psutil.virtual_memory()

        return {
            'rss_gb': memory_info.rss / (1024**3),
            'vms_gb': memory_info.vms / (1024**3),
            'available_gb': system_memory.available / (1024**3),
            'total_gb': system_memory.total / (1024**3),
            'percent': system_memory.percent
        }
    except Exception as e:
        print(f"âš ï¸ ãƒ¡ãƒ¢ãƒªæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            'rss_gb': 0.0, 'vms_gb': 0.0, 'available_gb': 0.0,
            'total_gb': 0.0, 'percent': 0.0
        }

def safe_file_size_check(filepath):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯

    Parameters:
    -----------
    filepath : str or Path
        ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Returns:
    --------
    float : ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º [GB]

    Raises:
    -------
    FileNotFoundError : ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    """
    filepath = Path(filepath)
    if not filepath.exists():
        raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")

    file_size_gb = filepath.stat().st_size / (1024**3)
    return file_size_gb

def monitor_memory_usage(stage_name="", warning_threshold_gb=6.0, critical_threshold_gb=8.0):
    """
    ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–ã—ã€å¿…è¦ã«å¿œã˜ã¦è­¦å‘Šã‚’è¡¨ç¤º

    Parameters:
    -----------
    stage_name : str
        è¨ˆç®—æ®µéšã®åå‰
    warning_threshold_gb : float
        è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ [GB]
    critical_threshold_gb : float
        å±é™ºãƒ¬ãƒ™ãƒ«ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ [GB]

    Returns:
    --------
    float : ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ [GB]
    bool : å±é™ºãƒ¬ãƒ™ãƒ«ã«é”ã—ãŸå ´åˆTrue
    """
    memory_info = get_memory_info()
    current_gb = memory_info['rss_gb']

    print(f"ğŸ“Š [{stage_name}] ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³:")
    print(f"   ãƒ—ãƒ­ã‚»ã‚¹ä½¿ç”¨é‡: {current_gb:.2f}GB")
    print(f"   ã‚·ã‚¹ãƒ†ãƒ åˆ©ç”¨å¯èƒ½: {memory_info['available_gb']:.2f}GB")
    print(f"   ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ç‡: {memory_info['percent']:.1f}%")

    # å±é™ºãƒ¬ãƒ™ãƒ«åˆ¤å®š
    is_critical = current_gb > critical_threshold_gb
    is_warning = current_gb > warning_threshold_gb

    if is_critical:
        print(f"ğŸš¨ ã€å±é™ºã€‘ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå±é™ºãƒ¬ãƒ™ãƒ«ã«åˆ°é”!")
        print(f"   {current_gb:.2f}GB > {critical_threshold_gb:.2f}GB")
        print(f"   æ¨å¥¨å¯¾å¿œ: å³åº§ã«ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã¾ãŸã¯ãƒ—ãƒ­ã‚»ã‚¹åœæ­¢")
        return current_gb, True

    elif is_warning:
        print(f"âš ï¸ ã€è­¦å‘Šã€‘ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒè­¦å‘Šãƒ¬ãƒ™ãƒ«ã«åˆ°é”")
        print(f"   {current_gb:.2f}GB > {warning_threshold_gb:.2f}GB")
        print(f"   æ¨å¥¨å¯¾å¿œ: ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ")
    else:
        print(f"âœ… ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ­£å¸¸")

    return current_gb, is_critical

def safe_load_large_data(filepath, max_size_gb=2.0, memory_check=True):
    """
    ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ã‚’é˜²ãå®‰å…¨ãªãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

    Parameters:
    -----------
    filepath : str or Path
        èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    max_size_gb : float
        è¨±å¯ã™ã‚‹æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º [GB]
    memory_check : bool
        ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡äº‹å‰ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†ã‹

    Returns:
    --------
    numpy.ndarray : èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿

    Raises:
    -------
    MemoryError : ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆ
    ValueError : ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã‚‹å ´åˆ
    """
    filepath = Path(filepath)

    print(f"ğŸ“ å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨èª­ã¿è¾¼ã¿é–‹å§‹: {filepath.name}")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
    try:
        file_size_gb = safe_file_size_check(filepath)
        print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_gb:.3f}GB")

        if file_size_gb > max_size_gb:
            raise ValueError(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™: {file_size_gb:.3f}GB > {max_size_gb:.3f}GB")

    except FileNotFoundError as e:
        print(f"âŒ {e}")
        raise

    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡äº‹å‰ãƒã‚§ãƒƒã‚¯
    if memory_check:
        current_memory, is_critical = monitor_memory_usage("èª­ã¿è¾¼ã¿å‰",
                                                         warning_threshold_gb=6.0,
                                                         critical_threshold_gb=8.0)

        # åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã¨å¿…è¦ãƒ¡ãƒ¢ãƒªã®æ¯”è¼ƒ
        memory_info = get_memory_info()
        available_gb = memory_info['available_gb']

        # çµŒé¨“å‰‡ï¼šnumpyãƒ•ã‚¡ã‚¤ãƒ«ã¯ç´„1.5å€ã®ãƒ¡ãƒ¢ãƒªã‚’ä¸€æ™‚çš„ã«ä½¿ç”¨
        estimated_memory_gb = file_size_gb * 1.5

        if estimated_memory_gb > available_gb * 0.8:  # åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã®80%ä»¥ä¸‹
            print(f"âš ï¸ ãƒ¡ãƒ¢ãƒªä¸è¶³ã®è­¦å‘Š:")
            print(f"   æ¨å®šå¿…è¦ãƒ¡ãƒ¢ãƒª: {estimated_memory_gb:.2f}GB")
            print(f"   åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {available_gb:.2f}GB")

            # è‡ªå‹•çš„ãªãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’è©¦è¡Œ
            print("ğŸ“‹ è‡ªå‹•ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
            optimize_memory_usage(force_gc=True, compact_arrays=False)

            # å†ãƒã‚§ãƒƒã‚¯
            memory_info_after = get_memory_info()
            available_after = memory_info_after['available_gb']

            if estimated_memory_gb > available_after * 0.8:
                raise MemoryError(f"ãƒ¡ãƒ¢ãƒªä¸è¶³: å¿…è¦{estimated_memory_gb:.2f}GB > åˆ©ç”¨å¯èƒ½{available_after:.2f}GB")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Ÿè¡Œ
    try:
        print("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Ÿè¡Œä¸­...")
        data = np.load(filepath)
        print(f"âœ… èª­ã¿è¾¼ã¿æˆåŠŸ: shape={data.shape}, dtype={data.dtype}")

        # èª­ã¿è¾¼ã¿å¾Œã®ãƒ¡ãƒ¢ãƒªçŠ¶æ³ç¢ºèª
        if memory_check:
            monitor_memory_usage("èª­ã¿è¾¼ã¿å¾Œ", warning_threshold_gb=6.0, critical_threshold_gb=8.0)

        return data

    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        raise MemoryError(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—: {e}")

def optimize_memory_usage(force_gc=True, compact_arrays=False):
    """
    ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–

    Parameters:
    -----------
    force_gc : bool
        å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    compact_arrays : bool
        é…åˆ—ã®å†é…ç½®ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ï¼ˆå®Ÿè£…äºˆç´„ï¼‰
    """
    print("ğŸ”§ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")

    # æœ€é©åŒ–å‰ã®ãƒ¡ãƒ¢ãƒªçŠ¶æ³
    before_info = get_memory_info()
    before_gb = before_info['rss_gb']

    if force_gc:
        print("   - ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ...")
        collected = gc.collect()
        print(f"   - å›åã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°: {collected}")

    # æœ€é©åŒ–å¾Œã®ãƒ¡ãƒ¢ãƒªçŠ¶æ³
    after_info = get_memory_info()
    after_gb = after_info['rss_gb']
    saved_gb = before_gb - after_gb

    print(f"ğŸ“Š æœ€é©åŒ–çµæœ:")
    print(f"   æœ€é©åŒ–å‰: {before_gb:.2f}GB")
    print(f"   æœ€é©åŒ–å¾Œ: {after_gb:.2f}GB")
    print(f"   å‰Šæ¸›é‡: {saved_gb:.2f}GB ({saved_gb/before_gb*100:.1f}%)")

def memory_warning_system(current_gb, threshold_gb, stage_name):
    """
    ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è­¦å‘Šã‚·ã‚¹ãƒ†ãƒ 

    Parameters:
    -----------
    current_gb : float
        ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ [GB]
    threshold_gb : float
        è­¦å‘Šé–¾å€¤ [GB]
    stage_name : str
        è¨ˆç®—æ®µéšå

    Returns:
    --------
    bool : è­¦å‘ŠãŒç™ºç”Ÿã—ãŸå ´åˆTrue
    """
    if current_gb > threshold_gb:
        print(f"\n{'='*70}")
        print(f"âš ï¸ ãƒ¡ãƒ¢ãƒªè­¦å‘Š: {stage_name}")
        print(f"   ç¾åœ¨ä½¿ç”¨é‡: {current_gb:.2f}GB > é–¾å€¤{threshold_gb:.2f}GB")
        print(f"   æ¨å¥¨å¯¾å¿œ: ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ")
        print(f"{'='*70}")

        # è‡ªå‹•çš„ãªãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
        optimize_memory_usage(force_gc=True)
        return True
    return False

def check_memory_critical(current_gb, critical_gb=8.0, emergency_stop=True):
    """
    é‡å¤§ãªãƒ¡ãƒ¢ãƒªä¸è¶³ã¸ã®ç·Šæ€¥å¯¾å¿œ

    Parameters:
    -----------
    current_gb : float
        ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ [GB]
    critical_gb : float
        å±é™ºé–¾å€¤ [GB]
    emergency_stop : bool
        ç·Šæ€¥åœæ­¢ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã©ã†ã‹

    Returns:
    --------
    bool : è¨ˆç®—ã‚’åœæ­¢ã™ã¹ãã‹ã©ã†ã‹
    """
    if current_gb > critical_gb:
        print(f"\n{'='*80}")
        print(f"ğŸ”´ é‡å¤§ãƒ¡ãƒ¢ãƒªä¸è¶³æ¤œå‡º - ç·Šæ€¥å¯¾å¿œãƒ¢ãƒ¼ãƒ‰")
        print(f"{'='*80}")
        print(f"ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {current_gb:.2f}GB")
        print(f"å±é™ºé–¾å€¤: {critical_gb:.2f}GB")
        print("-"*80)
        print("ç·Šæ€¥å¯¾å¿œç­–:")
        print("  1. è¨ˆç®—ã®å³åº§åœæ­¢")
        print("  2. ç¾åœ¨ã®çµæœã®ä¿å­˜")
        print("  3. ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®å®Ÿè¡Œ")
        print("  4. ã‚ˆã‚Šå°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§ã®å†é–‹")
        print(f"{'='*80}")

        if emergency_stop:
            print("ğŸš¨ ç·Šæ€¥åœæ­¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
            return True
        else:
            print("âš ï¸ è­¦å‘Šã®ã¿ã€‚è¨ˆç®—ã‚’ç¶™ç¶šã—ã¾ã™ã€‚")
            return False
    return False

# ==========================================================================

def check_diffusion_stability(dx, dy, dz_min, dt, k_max, rho_min, cp_min):
    """
    æ‹¡æ•£æ•°ã«ã‚ˆã‚‹æ•°å€¤å®‰å®šæ€§ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹é–¢æ•°

    Parameters:
    -----------
    dx, dy, dz_min : float
        x, y, zæ–¹å‘ã®æ ¼å­ã‚µã‚¤ã‚º [m] (dz_minã¯æœ€å°æ ¼å­ã‚µã‚¤ã‚º)
    dt : float
        æ™‚é–“åˆ»ã¿ [s]
    k_max : float
        æœ€å¤§ç†±ä¼å°ç‡ [W/(mÂ·K)]
    rho_min : float
        æœ€å°å¯†åº¦ [kg/mÂ³]
    cp_min : float
        æœ€å°æ¯”ç†± [J/(kgÂ·K)]

    Returns:
    --------
    max_diff_num : float
        æœ€å¤§æ‹¡æ•£æ•°
    diff_nums : tuple
        å„æ–¹å‘ã®æ‹¡æ•£æ•° (diff_num_x, diff_num_y, diff_num_z)
    """
    # æœ€å¤§ç†±æ‹¡æ•£ç‡ã®è¨ˆç®—ï¼ˆæœ€ã‚‚ä¸å®‰å®šãªæ¡ä»¶ï¼‰
    diffusivity_max = k_max / (rho_min * cp_min)

    # å„æ–¹å‘ã®æ‹¡æ•£æ•°è¨ˆç®—
    diff_num_x = diffusivity_max * dt / (dx**2)
    diff_num_y = diffusivity_max * dt / (dy**2)
    diff_num_z = diffusivity_max * dt / (dz_min**2)

    # æœ€å¤§æ‹¡æ•£æ•°ã®ç‰¹å®š
    max_diff_num = max(diff_num_x, diff_num_y, diff_num_z)

    # å®‰å®šæ€§åˆ¤å®šã¨è­¦å‘Šè¡¨ç¤º
    stability_threshold = 0.5  # æš—ç¤ºçš„ã‚¹ã‚­ãƒ¼ãƒ ã§ã‚‚æ¨å¥¨ã•ã‚Œã‚‹ä¸Šé™

    print("\n" + "="*60)
    print("         æ‹¡æ•£æ•°ã«ã‚ˆã‚‹æ•°å€¤å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯")
    print("="*60)
    print(f"ä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    print(f"  æ™‚é–“åˆ»ã¿ dt        : {dt:.4f} [s]")
    print(f"  æ ¼å­ã‚µã‚¤ã‚º dx      : {dx*1e3:.3f} [mm]")
    print(f"  æ ¼å­ã‚µã‚¤ã‚º dy      : {dy*1e3:.3f} [mm]")
    print(f"  æœ€å°æ ¼å­ dz_min    : {dz_min*1e6:.1f} [Î¼m]")
    print(f"  æœ€å¤§ç†±ä¼å°ç‡ k_max : {k_max:.2f} [W/(mÂ·K)]")
    print(f"  æœ€å°å¯†åº¦ Ï_min     : {rho_min:.0f} [kg/mÂ³]")
    print(f"  æœ€å°æ¯”ç†± cp_min    : {cp_min:.1f} [J/(kgÂ·K)]")
    print(f"  æœ€å¤§ç†±æ‹¡æ•£ç‡      : {diffusivity_max*1e6:.2f} [mmÂ²/s]")
    print("-"*60)
    print(f"æ‹¡æ•£æ•°è¨ˆç®—çµæœ:")
    print(f"  xæ–¹å‘æ‹¡æ•£æ•°       : {diff_num_x:.4f}")
    print(f"  yæ–¹å‘æ‹¡æ•£æ•°       : {diff_num_y:.4f}")
    print(f"  zæ–¹å‘æ‹¡æ•£æ•°       : {diff_num_z:.4f}")
    print(f"  æœ€å¤§æ‹¡æ•£æ•°        : {max_diff_num:.4f}")
    print("-"*60)

    if max_diff_num > stability_threshold:
        print(f"âš ï¸  è­¦å‘Š: æ‹¡æ•£æ•°ãŒå¤§ãã™ãã¾ã™!")
        print(f"   æœ€å¤§æ‹¡æ•£æ•° {max_diff_num:.4f} > æ¨å¥¨ä¸Šé™ {stability_threshold}")
        print(f"   æ•°å€¤ä¸å®‰å®šæ€§ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print()

        # å®‰å…¨ãªæ™‚é–“åˆ»ã¿ã®æ¨å¥¨
        safe_dt_x = stability_threshold * (dx**2) / diffusivity_max
        safe_dt_y = stability_threshold * (dy**2) / diffusivity_max
        safe_dt_z = stability_threshold * (dz_min**2) / diffusivity_max
        safe_dt = min(safe_dt_x, safe_dt_y, safe_dt_z)

        print(f"æ¨å¥¨æ™‚é–“åˆ»ã¿:")
        print(f"  xæ–¹å‘åˆ¶ç´„ã«ã‚ˆã‚‹ dt â‰¤ {safe_dt_x*1e3:.3f} [ms]")
        print(f"  yæ–¹å‘åˆ¶ç´„ã«ã‚ˆã‚‹ dt â‰¤ {safe_dt_y*1e3:.3f} [ms]")
        print(f"  zæ–¹å‘åˆ¶ç´„ã«ã‚ˆã‚‹ dt â‰¤ {safe_dt_z*1e6:.1f} [Î¼s]")
        print(f"  æ¨å¥¨æœ€å¤§æ™‚é–“åˆ»ã¿  : {safe_dt*1e6:.1f} [Î¼s]")
        print()

        # å®Ÿç”¨çš„ãªå¯¾å¿œç­–ã®æç¤º
        print("ğŸ“‹ å®Ÿç”¨çš„ãªå¯¾å¿œç­–:")
        if safe_dt < dt * 0.01:  # æ¨å¥¨å€¤ãŒç¾åœ¨å€¤ã®1/100ä»¥ä¸‹ã®å ´åˆ
            print("  1. zæ–¹å‘æ ¼å­ã®ç²—ã„åŒ–ï¼ˆè¡¨é¢ä»˜è¿‘ã®ç²¾åº¦ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼‰")
            print("  2. æš—ç¤ºçš„è§£æ³•ã®å®‰å®šæ€§ã«ä¾å­˜ã—ãŸè¨ˆç®—ã®ç¶™ç¶š")
            print("  3. å±€æ‰€çš„æ™‚é–“åˆ»ã¿é©å¿œæ³•ã®å°å…¥")
            print("  4. ã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–ãƒ¡ãƒƒã‚·ãƒ¥æ³•ã®æ¤œè¨")
        else:
            print(f"  1. æ™‚é–“åˆ»ã¿ã‚’ {safe_dt*1e3:.3f} msä»¥ä¸‹ã«å¤‰æ›´")
            print("  2. è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®")

        warnings.warn(f"æ‹¡æ•£æ•°ãŒæ¨å¥¨ä¸Šé™ã‚’è¶…ãˆã¦ã„ã¾ã™: {max_diff_num:.4f} > {stability_threshold}")
    else:
        print(f"âœ… å®‰å®šæ€§OK: æ‹¡æ•£æ•° {max_diff_num:.4f} â‰¤ æ¨å¥¨ä¸Šé™ {stability_threshold}")

        # ä½™è£•åº¦ã®è¨ˆç®—
        safety_factor = stability_threshold / max_diff_num
        print(f"   å®‰å…¨ä½™è£•åº¦: {safety_factor:.2f}å€")

    print("="*60)

    return max_diff_num, (diff_num_x, diff_num_y, diff_num_z)


'''
Define the Function to Find the Files whitch can Match Name format["SUS" + number + ".MAT"]
Sort the Files by the Keys of Extract Numbers from the Small to Large
'''

def extract_sorted_mat_files(folder_path):
    def extract_number(file_name):
        match = re.match(r'SUS(\d+)\.MAT', file_name)
        return int(match.group(1)) if match else -1
    
    files = []
    for f in os.listdir(folder_path):
        if f.startswith('SUS') and f.endswith('.MAT'):
            files.append(f)
    return sorted(files, key = extract_number)

'''
Load the Temperature Variation Array of a Specific Region from IR Temperature File
Region: (i_start, j_start) to (i_end, j_end)
'''
def load_region_temperature(folder_path, i_range, j_range):
    i_start, i_end = i_range
    j_start, j_end = j_range

    mat_files = extract_sorted_mat_files(folder_path)
    num_frames = len(mat_files)
    
    height = i_end - i_start + 1
    width = j_end - j_start + 1

    region_data_K = np.zeros((height, width, num_frames))
    
    # read temperature array of a specific location from IR camera matlac files,
    # preserve the temperature data to region_data_K & region_data_C

    for idx, file in enumerate(mat_files):
        
        mat_data = loadmat(os.path.join(folder_path, file))
        frame_data = mat_data[file[:-4]]
        
        sub_region = frame_data[i_start:i_end + 1, j_start:j_end + 1]
        region_data_K[:, :, idx] = sub_region

    return region_data_K, num_frames

'''
Define the Physical properties of Calculation Region 
'''
nz = 20                                                                        # grid numbers at x, y, z direction
dx, dy = 0.12e-3, (0.12e-3 * sin(radians(80)) / sin(radians(45)))              # real x_direction & y_direction length for a single pixel 
Lz = 0.5e-3                                                                    # real x, y, z direction length
 
stretch_factor = 3   
# Grid faces plotting for Z direction
z_faces = np.linspace(1, 0, nz + 1)                                                            # Generate nz+1 grid surfaces for nz grids

# Irregular grid generation from regular grid faces
z_faces = Lz - (Lz / (np.exp(stretch_factor) - 1)) * (np.exp(stretch_factor * z_faces) - 1)    # Generate stretched grid 

z_centers = np.zeros(nz)                                  # Center coordinates for nz grids

z_centers[0] = z_faces[0]                                 # The Bottom-most grid center coordinate(half CV/ grid center point overlaps the Bottom-most boundary)
z_centers[-1] = z_faces[-1]                               # The top-most grid center coordinate(half CV/ grid center point overlaps the top-most boundary)
z_centers[1:-1] = (z_faces[1:-2] + z_faces[2:-1]) / 2     # Intermediate grids
                
# Boundary component Calculation
dz = np.diff(z_faces)                                # Calculate every-grid size

dz_t = np.zeros(nz)                                  # Top component_delta_z_t
dz_t[-1] = np.inf                                    # Top component_delta_z_t for top-most CV
dz_t[:-1] = z_centers[1:] - z_centers[:-1]           # Other Top component_delta_z_t

dz_b = np.zeros(nz)                                  # Bottom component_delta_z_b
dz_b[0] = np.inf                                     # Bottom component_delta_z_b for Bottom-most CV
dz_b[1:] = z_centers[1:] - z_centers[:-1]            # Other Bottom component_delta_z_b

# debug
print("z_faces : ", z_faces)
print("z_centers : ", z_centers)
print("dz : ", dz)
print("dz_t : ", dz_t)
print("dz_b : ", dz_b)
#

'''
=== Direct problem solver  ===
=== Sensitivity problem solver ===

coefficients(a*) for A whitch used csr_matrix (Compressed Sparse Row matrix: CSR) class
and right hand side (b) building for direct heat conduction problems for 1 time step (Ax = b)
'''
@njit(parallel=True, fastmath=False)
def coeffs_and_rhs_building_DHCP(T_initial, q_surface, rho, cp, k, dx, dy, dz, dz_b, dz_t, dt):
    ni, nj, nk = T_initial.shape
    N = ni * nj * nk
    
    a_w = np.zeros(N)
    a_e = np.zeros(N)
    a_s = np.zeros(N)
    a_n = np.zeros(N)
    a_b = np.zeros(N)
    a_t = np.zeros(N)
    a_p = np.zeros(N)
    
    b   = np.zeros(N)
    
    for p in prange(N):
        i = p % ni
        j = (p // ni) % nj
        k_ijk = p // (ni * nj)
        
        dz_k = dz[k_ijk]
        dz_t_k = dz_t[k_ijk]
        dz_b_k = dz_b[k_ijk]
        
        k_p = k[i, j, k_ijk]
        
        a_p_0 = rho * cp[i, j, k_ijk] * dx * dy * dz_k / dt
        
        a_w[p] = 0.0 if j == 0                 else (2 * k_p * k[i, j-1, k_ijk] / (k_p + k[i, j-1, k_ijk])) * dy * dz_k / dx
        a_e[p] = 0.0 if j == nj-1              else (2 * k_p * k[i, j+1, k_ijk] / (k_p + k[i, j+1, k_ijk])) * dy * dz_k / dx
        a_s[p] = 0.0 if i == 0                 else (2 * k_p * k[i-1, j, k_ijk] / (k_p + k[i-1, j, k_ijk])) * dx * dz_k / dy
        a_n[p] = 0.0 if i == ni-1              else (2 * k_p * k[i+1, j, k_ijk] / (k_p + k[i+1, j, k_ijk])) * dx * dz_k / dy
        a_b[p] = 0.0 if k_ijk == 0             else (2 * k_p * k[i, j, k_ijk-1] / (k_p + k[i, j, k_ijk-1])) * dx * dy / dz_b_k
        a_t[p] = 0.0 if k_ijk == nk-1          else (2 * k_p * k[i, j, k_ijk+1] / (k_p + k[i, j, k_ijk+1])) * dx * dy / dz_t_k
        
        a_p[p] = a_w[p] + a_e[p] + a_s[p] + a_n[p] + a_b[p] + a_t[p] + a_p_0
        
        rhs = a_p_0 * T_initial[i, j, k_ijk]
        
        if k_ijk == nk - 1:
            rhs += q_surface[i, j] * dx * dy
        b[p] = rhs
        
    return a_w, a_e, a_s, a_n, a_b, a_t, a_p, b

def assemble_A_DHCP(ni, nj, nk, a_w, a_e, a_s, a_n, a_b, a_t, a_p):
    N = ni * nj * nk
    
    off_i = 1           # offsets for i direction (south & north)
    off_j = ni          # offsets for j direction (west & east)
    off_k = ni * nj     # offsets for k direction (bottom & top)

    D0   = a_p.copy()                 # len N
    D_im1 = -a_s[off_i: ]        # len N-1
    D_jm1 = -a_w[off_j: ]        # len N-ni
    D_km1 = -a_b[off_k: ]        # len N-ni*nj
    
    D_ip1 = -a_n[ :N-off_i]         # len N-1
    D_jp1 = -a_e[ :N-off_j]         # len N-ni
    D_kp1 = -a_t[ :N-off_k]         # len N-ni*nj

    A_csr = diags(
        diagonals=[D0, D_im1, D_jm1, D_km1, D_kp1, D_jp1, D_ip1],
        offsets=[0, -off_i, -off_j, -off_k, off_k, off_j, off_i],
        shape=(N, N), format="csr"
    )
    
    return A_csr


def multiple_time_step_solver_DHCP(T_initial, q_surface, nt, rho, cp_coeffs, k_coeffs,
                                       dx, dy, dz, dz_b, dz_t, dt, rtol, maxiter):
    '''
    nt: time step number for Temperature measurement (T_measure)
    T_initial.shape = (ni, nj, nk)
    q_surface:  | heat flux on upper surface
                | shape = (nt-1, ni, nj)
    T_all: 3D Temperature distributation at every time step

    return: T_all.shape = (nt, ni, nj, nk)
    '''

    ni, nj, nk = T_initial.shape
    N = ni * nj * nk

    # å¤§è¦æ¨¡å•é¡Œã§ã®ãƒ¡ãƒ¢ãƒªç›£è¦–ï¼ˆDHCPé–‹å§‹æ™‚ï¼‰
    if N > 100000:  # ç´„10ä¸‡è¦ç´ ä»¥ä¸Šã®å ´åˆ
        current_memory, is_critical = monitor_memory_usage(f"DHCPé–‹å§‹(N={N})",
                                                          warning_threshold_gb=6.0,
                                                          critical_threshold_gb=8.0)
        if is_critical:
            raise MemoryError("DHCP: ãƒ¡ãƒ¢ãƒªä¸è¶³ã«ã‚ˆã‚Šè¨ˆç®—ã‚’åœæ­¢")

    T_all = np.empty((nt, ni, nj, nk))
    T_all[0] = T_initial

    x0 = T_initial.ravel(order = "F").copy()
    
    for t in range(1, nt):
        
        cp, k = thermal_properties_calculator(T_all[t-1], cp_coeffs, k_coeffs)
        
        a_w, a_e, a_s, a_n, a_b, a_t, a_p, b = coeffs_and_rhs_building_DHCP(T_all[t-1], q_surface[t-1], rho, cp, k, dx, dy, dz, dz_b, dz_t, dt)
        
        A_csr = assemble_A_DHCP(ni, nj, nk, a_w, a_e, a_s, a_n, a_b, a_t, a_p)

        diag = A_csr.diagonal()
        inv_diag = np.where(diag != 0.0, 1.0/diag, 0.0)  # é˜²é™¤é›¶
        
        def Mv(z):
            return inv_diag * z
        
        M = LinearOperator(A_csr.shape, matvec = Mv)
        
        x, info = cg(A_csr, b, M = M, rtol = rtol, maxiter = maxiter, x0 = x0)

        if info > 0:
            print(f"[è­¦å‘Š][t={t}] Krylovæ³•ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸ (info={info})")
        elif info < 0:
            print(f"[ã‚¨ãƒ©ãƒ¼][t={t}] Krylovæ³•ã®å…¥åŠ›ãŒä¸æ­£ã§ã™ (info={info})")

        # å†™å…¥ä¸çƒ­å¯åŠ¨
        T_all[t] = x.reshape((ni, nj, nk), order="F")
        x0 = x

        # æ•°å€¤ç•°å¸¸æ¤œå‡ºï¼ˆDHCPæ¸©åº¦å ´ï¼‰
        is_valid, status_msg = check_temperature_field(T_all[t], timestep=t, dx=dx, dy=dy, dz=dz)
        if not is_valid:
            print(f"[DHCPè­¦å‘Š][t={t}] æ¸©åº¦å ´ç•°å¸¸: {status_msg}")
            # é‡å¤§ãªç•°å¸¸ã®å ´åˆã¯è¨ˆç®—ã‚’åœæ­¢ã™ã‚‹é¸æŠè‚¢ã‚‚ã‚ã‚‹
            # ç¾åœ¨ã¯è­¦å‘Šã®ã¿ã§ç¶™ç¶š


    return T_all
    
'''
=== Adjoint problem solver  ===

coefficients(a*) for A whitch used csr_matrix (Compressed Sparse Row matrix: CSR) class
and right hand side (b) building for adjoint problem for all time step (Ax = b)
'''
@njit(parallel=True, fastmath=False)
def coeffs_and_rhs_building_Adjoint(lambda_initial, T_cal, Y_obs, rho, cp, k, dx, dy, dz, dz_b, dz_t, dt):
    ni, nj, nk = lambda_initial.shape
    N = ni * nj * nk
    
    a_w = np.zeros(N)
    a_e = np.zeros(N)
    a_s = np.zeros(N)
    a_n = np.zeros(N)
    a_b = np.zeros(N)
    a_t = np.zeros(N)
    a_p = np.zeros(N)
    
    b   = np.zeros(N)
    
    for p in prange(N):
        i = p % ni
        j = (p // ni) % nj
        k_ijk = p // (ni * nj)
        
        dz_k = dz[k_ijk]
        dz_t_k = dz_t[k_ijk]
        dz_b_k = dz_b[k_ijk]
        
        k_p = k[i, j, k_ijk]
        
        a_p_0 = rho * cp[i, j, k_ijk] * dx * dy * dz_k / dt
        
        a_w[p] = 0.0 if j == 0                 else (2 * k_p * k[i, j-1, k_ijk] / (k_p + k[i, j-1, k_ijk])) * dy * dz_k / dx
        a_e[p] = 0.0 if j == nj-1              else (2 * k_p * k[i, j+1, k_ijk] / (k_p + k[i, j+1, k_ijk])) * dy * dz_k / dx
        a_s[p] = 0.0 if i == 0                 else (2 * k_p * k[i-1, j, k_ijk] / (k_p + k[i-1, j, k_ijk])) * dx * dz_k / dy
        a_n[p] = 0.0 if i == ni-1              else (2 * k_p * k[i+1, j, k_ijk] / (k_p + k[i+1, j, k_ijk])) * dx * dz_k / dy
        a_b[p] = 0.0 if k_ijk == 0             else (2 * k_p * k[i, j, k_ijk-1] / (k_p + k[i, j, k_ijk-1])) * dx * dy / dz_b_k
        a_t[p] = 0.0 if k_ijk == nk-1          else (2 * k_p * k[i, j, k_ijk+1] / (k_p + k[i, j, k_ijk+1])) * dx * dy / dz_t_k
        
        a_p[p] = a_w[p] + a_e[p] + a_s[p] + a_n[p] + a_b[p] + a_t[p] + a_p_0
        
        rhs = a_p_0 * lambda_initial[i, j, k_ijk]
        
        if k_ijk == 0:
            rhs += 2 * (T_cal[i, j] - Y_obs[i, j]) * dx * dy
        b[p] = rhs
        
    return a_w, a_e, a_s, a_n, a_b, a_t, a_p, b

def assemble_A_Adjoint(ni, nj, nk, a_w, a_e, a_s, a_n, a_b, a_t, a_p):
    N = ni * nj * nk
    
    off_i = 1           # offsets for i direction (south & north)
    off_j = ni          # offsets for j direction (west & east)
    off_k = ni * nj     # offsets for k direction (bottom & top)

    D0   = a_p.copy()                 # len N
    D_im1 = -a_s[off_i: ]        # len N-1
    D_jm1 = -a_w[off_j: ]        # len N-ni
    D_km1 = -a_b[off_k: ]        # len N-ni*nj
    
    D_ip1 = -a_n[ :N-off_i]         # len N-1
    D_jp1 = -a_e[ :N-off_j]         # len N-ni
    D_kp1 = -a_t[ :N-off_k]         # len N-ni*nj

    A_csr = diags(
        diagonals=[D0, D_im1, D_jm1, D_km1, D_kp1, D_jp1, D_ip1],
        offsets=[0, -off_i, -off_j, -off_k, off_k, off_j, off_i],
        shape=(N, N), format="csr"
    )
    
    return A_csr


def multiple_time_step_solver_Adjoint(T_cal, Y_obs, nt, rho, cp_coeffs, k_coeffs,
                                       dx, dy, dz, dz_b, dz_t, dt, rtol, maxiter):
    '''
    nt: time step number for Temperature measurement (Y_obs)

    T_cal: 3D Temperature distributation at every time step based on DHCP solver
            T_cal.shape = (nt, ni, nj, nk)

    Y_obs: 2D Temperature distributation at every time step based on IR camera reading

    return: lambda_field.shape = (nt, ni, nj, nk)
    '''

    ni, nj, nk = T_cal[0].shape
    N = ni * nj * nk

    # å¤§è¦æ¨¡å•é¡Œã§ã®ãƒ¡ãƒ¢ãƒªç›£è¦–ï¼ˆAdjointé–‹å§‹æ™‚ï¼‰
    if N > 100000:  # ç´„10ä¸‡è¦ç´ ä»¥ä¸Šã®å ´åˆ
        current_memory, is_critical = monitor_memory_usage(f"Adjointé–‹å§‹(N={N})",
                                                          warning_threshold_gb=6.0,
                                                          critical_threshold_gb=8.0)
        if is_critical:
            raise MemoryError("Adjoint: ãƒ¡ãƒ¢ãƒªä¸è¶³ã«ã‚ˆã‚Šè¨ˆç®—ã‚’åœæ­¢")

    lambda_field = np.empty_like(T_cal)
    lambda_field[-1] = 0

    lambda_initial = lambda_field[-1]

    x0 = lambda_initial.ravel(order = "F").copy()
    
    for t in range(nt-2, -1, -1):
        
        lambda_initial = lambda_field[t+1]
        
        cp, k = thermal_properties_calculator(T_cal[t], cp_coeffs, k_coeffs)
        
        a_w, a_e, a_s, a_n, a_b, a_t, a_p, b = coeffs_and_rhs_building_Adjoint(
            lambda_initial, T_cal[t][:,:,0], Y_obs[t], rho, cp, k, dx, dy, dz, dz_b, dz_t, dt)
        
        A_csr = assemble_A_Adjoint(ni, nj, nk, a_w, a_e, a_s, a_n, a_b, a_t, a_p)

        diag = A_csr.diagonal()
        inv_diag = np.where(diag != 0.0, 1.0/diag, 0.0)  # é˜²é™¤é›¶
        
        def Mv(z):
            return inv_diag * z
        
        M = LinearOperator(A_csr.shape, matvec = Mv)
        
        x, info = cg(A_csr, b, M = M, rtol = rtol, maxiter = maxiter, x0 = x0)


        if info > 0:
            print(f"[è­¦å‘Š][t={t}] Krylovæ³•ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸ (info={info})")
        elif info < 0:
            print(f"[ã‚¨ãƒ©ãƒ¼][t={t}] Krylovæ³•ã®å…¥åŠ›ãŒä¸æ­£ã§ã™ (info={info})")

        # å†™å…¥ä¸çƒ­å¯åŠ¨
        lambda_field[t] = x.reshape((ni, nj, nk), order="F")
        x0 = x

        # æ•°å€¤ç•°å¸¸æ¤œå‡ºï¼ˆAdjointéšä¼´å ´ï¼‰
        is_valid, status_msg = check_adjoint_field(lambda_field[t], timestep=t, dx=dx, dy=dy, dz=dz)
        if not is_valid:
            print(f"[Adjointè­¦å‘Š][t={t}] éšä¼´å ´ç•°å¸¸: {status_msg}")

    return lambda_field

'''
=== CGM for one time window ===
Prediction of the surface heat flux by using the Conjugate gradient method: CGM
'''

def global_CGM_time(T_init, Y_obs, q_init, dx, dy, dz, dz_b, dz_t, dt, 
                        rho, cp_coeffs, k_coeffs, CGM_iteration = 20000
                        ):
    
    nt = Y_obs.shape[0]                             # Y_obs shape(nt, ni, nj) Observation Temperature array for whole time domain
    ni, nj, nk = T_init.shape                       # T_init shape(ni, nj, nk) Initial temperature distribution
    q = q_init.copy()                               # (nt-1, ni, nj) Initial surface heat flux guess
    
    J_hist = []                                     # J_list J saving for every iteration
    
    M = ni * nj
    sigma = 1.8                                                 # Measurement error assumption
    epsilon = M * (sigma ** 2) * (nt-1)                         # iteration stop criteration
    
    grad = np.zeros_like(q)                         # grad_J_q shape(nt-1, ni, nj) heat flux change gradient for upper surface 
    grad_last = np.zeros_like(q)                    # grad_J_q_last shape(nt-1, ni, nj) heat flux change gradient for upper surface at the last iteration
    
    bottom_idx, top_idx = 0, -1
    # eps safeguards divisions; adjust if the solver stalls
    eps = 1e-12
    dire_reset_every = 5
    
    p_n_last = np.zeros_like(q)
    
    # â€”â€” å¹³å°æ£€æµ‹å‚æ•° â€”â€” #
    P = 10                      # è¿‘ P æ¬¡å¹³å‡
    eta = 1e-4                  # å¹³å‡ç›¸å¯¹ä¸‹é™é˜ˆå€¼ï¼ˆ<0.01%ï¼‰
    min_iter = 10               # æœ€å°è¿­ä»£æ•°ï¼Œé˜²æ—©åœ

    def _dot(a, b):
        return float(np.tensordot(a, b, axes = a.ndim))

    # CGMãƒ«ãƒ¼ãƒ—é–‹å§‹å‰ã®ãƒ¡ãƒ¢ãƒªçŠ¶æ³ç¢ºèª
    current_memory, is_critical = monitor_memory_usage("CGMãƒ«ãƒ¼ãƒ—é–‹å§‹",
                                                      warning_threshold_gb=6.0,
                                                      critical_threshold_gb=8.0)
    if is_critical:
        print("ğŸš¨ ãƒ¡ãƒ¢ãƒªä¸è¶³ã®ãŸã‚è¨ˆç®—ã‚’é–‹å§‹ã§ãã¾ã›ã‚“")
        return q, T_init, []

    for it in range(CGM_iteration):
        t0 = time.time()

        # å®šæœŸçš„ãªãƒ¡ãƒ¢ãƒªç›£è¦–ï¼ˆ10åå¾©ã”ã¨ï¼‰
        if it % 10 == 0 or it < 5:  # æœ€åˆã®5å›ã¯æ¯å›ã€ãã®å¾Œã¯10å›ã”ã¨
            current_memory, is_critical = monitor_memory_usage(f"CGMåå¾©{it}",
                                                              warning_threshold_gb=6.0,
                                                              critical_threshold_gb=8.0)
            if is_critical:
                print(f"ğŸš¨ ãƒ¡ãƒ¢ãƒªä¸è¶³ã«ã‚ˆã‚Šè¨ˆç®—ã‚’åœæ­¢ã—ã¾ã™ï¼ˆåå¾©{it}ï¼‰")
                break

        # Step 1: direct problem for all time steps
        T_cal = multiple_time_step_solver_DHCP(
            T_init, q, nt, rho, cp_coeffs, k_coeffs,
            dx, dy, dz, dz_b, dz_t, dt,
            rtol = 1e-6, maxiter = 20000
            )
            
        # Step 2: stopping criterion check
        res_T = T_cal[1:, :, :, bottom_idx] - Y_obs[1:] # shape = (nt-1, ni, nj)
        delta_T = np.abs(res_T)
        J = float(np.tensordot(res_T, res_T, axes = res_T.ndim))
        J_hist.append(J)
        
        # ================== ç»Ÿä¸€åœæœºåˆ¤æ–­ï¼ˆDiscrepancy & Calculation Bottleneckï¼‰ ================== #
        # Discrepancyï¼ˆæˆåŠŸåœæœºï¼‰
        if it >= min_iter and J < epsilon and delta_T.max() <= sigma:
            print(f"[åœæ­¢] Discrepancyæ¡ä»¶ã‚’æº€è¶³ï¼šJ={J:.4e} < {epsilon:.4e} ã‹ã¤ max|Î”T|={delta_T.max():.3e} â‰¤ Ïƒ={sigma}")
            break

        # å¹³å°ï¼šè¿‘ P æ¬¡å¹³å‡ç›¸å¯¹ä¸‹é™å¾ˆå°ï¼ˆè¿›å±•åˆ°ç“¶é¢ˆï¼‰
        rel_drop_avg = None
        if len(J_hist) >= P + 1:
            drops = []
            for i in range(-P, 0):
                prev_i, cur_i = J_hist[i-1], J_hist[i]
                drops.append(max(0.0, (prev_i - cur_i) / (abs(prev_i) + eps)))
            rel_drop_avg = sum(drops) / P

        if it >= min_iter and rel_drop_avg is not None and rel_drop_avg < eta:
            print(f"[åœæ­¢] ãƒ—ãƒ©ãƒˆãƒ¼ï¼šrel_drop_avg={rel_drop_avg:.3e} < eta={eta:.1e}ï¼ˆç›´è¿‘{P}ã‚¹ãƒ†ãƒƒãƒ—ã®å¹³å‡é€²å±•ãŒå¾®å°ï¼‰")
            break
        # ================== ç»Ÿä¸€åœæœºåˆ¤æ–­ç»“æŸ ================== #
        
        # Step 3: adjoint problem solution
        lambda_field =  multiple_time_step_solver_Adjoint(
            T_cal, Y_obs, nt, rho, cp_coeffs, k_coeffs,
            dx, dy, dz, dz_b, dz_t, dt,
            rtol = 1e-8, maxiter = 20000
            )

        # CGMãƒ¬ãƒ™ãƒ«ã§ã®åŒ…æ‹¬çš„ç•°å¸¸æ¤œå‡ºï¼ˆéšä¼´å ´ï¼‰
        is_lambda_valid, lambda_status = check_adjoint_field(lambda_field, iteration=it, dx=dx, dy=dy, dz=dz)
        if not is_lambda_valid:
            print(f"[CGMè­¦å‘Š][åå¾©{it}] éšä¼´å ´å…¨ä½“ç•°å¸¸: {lambda_status}")
            # å¾“æ¥ã®ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ã‚‚ä¿æŒï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
            if not np.isfinite(lambda_field).all():
                print(f"[CGMé‡å¤§][åå¾©{it}] lambda_fieldã§NaN/InfãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ - è¨ˆç®—åœæ­¢ã‚’æ¤œè¨")
            
        # Step 4: gradient calculation for all time steps
        for n in range(nt - 1):
            grad[n] = lambda_field[n][:, :, top_idx]                 # gradient distributation field of the top surface (nt, ni, nj)

        # å‹¾é…å ´ã®ç•°å¸¸æ¤œå‡º
        is_grad_valid, grad_status = check_flux_field(grad, iteration=it, dx=dx, dy=dy)
        if not is_grad_valid:
            print(f"[CGMè­¦å‘Š][åå¾©{it}] å‹¾é…å ´ç•°å¸¸: {grad_status}")

        # Step 5: conjugate gradient direction calculation
        if it == 0 or _dot(grad, p_n_last) <= 0 or it % dire_reset_every == 0:
            p_n = grad.copy()
            gamma = 0    
        else:
            y = grad - grad_last
            denom = _dot(grad_last,grad_last) + eps
            gamma = max(0, _dot(grad, y) / denom)
            p_n_candidate = grad + gamma * p_n_last
            
            if _dot(grad, p_n_candidate) > 0:
                p_n = p_n_candidate
                
            else:
                p_n = grad.copy()

        p_n_last = p_n.copy()
        
        # Step 6: set delta_q = p_n on top surfaceï¼Œsolve the sensitivity problem
        dT_init = np.zeros_like(T_init)
        dT = multiple_time_step_solver_DHCP(
                dT_init, p_n, nt, rho, cp_coeffs, k_coeffs,
                dx, dy, dz, dz_b, dz_t, dt,
                rtol = 1e-8, maxiter = 20000
                )

        # æ„Ÿåº¦å ´dTã®ç•°å¸¸æ¤œå‡º
        is_dT_valid, dT_status = check_temperature_field(dT, dx=dx, dy=dy, dz=dz)
        if not is_dT_valid:
            print(f"[CGMè­¦å‘Š][åå¾©{it}] æ„Ÿåº¦å ´dTç•°å¸¸: {dT_status}")

        # Step 7: search step size
        Sp = dT[1:, :, :, bottom_idx]
        assert res_T.shape == Sp.shape, (res_T.shape, Sp.shape)
        numerator   = float(np.tensordot(res_T, Sp, axes=res_T.ndim))
        denominator = float(np.tensordot(Sp,  Sp,  axes=Sp.ndim))
        
        beta = numerator / (denominator + eps)
        
        # step size limitation
        beta_max = 1e8

        if it == 0 and abs(beta) > beta_max:
            print(f"  [WARN] beta clipped: {beta:.2e} => {np.sign(beta)*beta_max:.2e}")
            beta = np.clip(beta, -beta_max, beta_max)
        
        # print_interval = 10
        # if it % print_interval == 0 or it == 0 or it == CGM_iteration - 1:
            
        ''' relative desent rate '''    
        rel_drop = None
        if len(J_hist) >= 2:
            rel_drop = abs(J_hist[-1] - J_hist[-2]) / (J_hist[-2])
        
        wall_s = time.time() - t0
        print(f"@ ___ Iter {it:3d} ___ @ wall_s = {wall_s:.3f}s")
        print(f"J = {J:.5e}, beta = {beta:.4e}, rel_drop = {None if rel_drop is None else f'{rel_drop:.3e}'}")
        print(f"|T - Y|: max={delta_T.max():.3e}, min={delta_T.min():.3e}, mean={delta_T.mean():.3e}")
        print(f"grad: min={grad.min():.4e}, max={grad.max():.4e}, mean={grad.mean():.4e}")
        print(f"dT:   min={dT[1:].min():.4e}, max={dT[1:].max():.4e}, mean={dT[1:].mean():.4e}")
        print(f"q:    min={q.min():.4e}, max={q.max():.4e}, mean={q.mean():.4e}") 
        print(f"denominator at iter {it}: {denominator:.4e}")
   
        # æ›´æ–°q
        q = q - beta * p_n

        # ç†±æµæŸqã®ç•°å¸¸æ¤œå‡º
        is_q_valid, q_status = check_flux_field(q, iteration=it, dx=dx, dy=dy)
        if not is_q_valid:
            print(f"[CGMè­¦å‘Š][åå¾©{it}] ç†±æµæŸqç•°å¸¸: {q_status}")

        grad_last = grad.copy()
        
    return q, T_cal[-1], J_hist


def sliding_window_CGM_q_saving(
    Y_obs, T0, dx, dy, dz, dz_b, dz_t, dt, rho, cp_coeffs, k_coeffs,
    window_size, overlap, q_init_value, filename, CGM_iteration=20000
):
    nt = Y_obs.shape[0]
    T_init = T0.copy()
    ni, nj, nk = T_init.shape

    start_idx = 0
    q_total = []
    prev_q_win = None

    safety_counter = 0
    safety_limit = nt * 5  # ç»éªŒå€¼

    while start_idx < nt - 1:
        safety_counter += 1
        if safety_counter > safety_limit:
            print("Safety break: too many iterations, check overlap/window settings.")
            break

        # å½“å‰å¯ç”¨çª—é•¿
        max_L = min(window_size, (nt - 1) - start_idx)
        end_idx = start_idx + max_L
        Y_obs_win = Y_obs[start_idx: end_idx + 1, :, :]

        # è¯¥çª—çš„åˆå§‹çƒ­æµ
        if prev_q_win is None:
            q_init_win = np.full((max_L, ni, nj), q_init_value, dtype=float)
        else:
            q_init_win = np.empty((max_L, ni, nj), dtype=float)
            L_overlap = min(overlap, max_L, prev_q_win.shape[0])
            if L_overlap > 0:
                q_init_win[:L_overlap] = prev_q_win[-L_overlap:]
            if L_overlap < max_L:
                edge = prev_q_win[-1]
                q_init_win[L_overlap:] = edge

        start_time_one_window = time.time()
        q_win, T_win_last, J_hist = global_CGM_time(
            T_init, Y_obs_win, q_init_win, dx, dy, dz, dz_b, dz_t, dt,
            rho, cp_coeffs, k_coeffs, CGM_iteration=CGM_iteration
        )
        end_time_one_window = time.time()

        prev_q_win = q_win.copy()

        # æ‹¼æ¥ qï¼ˆå¯¹é‡å éƒ¨åˆ†åšå¹³å‡ï¼‰
        if len(q_total) == 0:
            q_total.append(q_win)
        else:
            overlap_steps = min(overlap, q_win.shape[0], q_total[-1].shape[0])
            if overlap_steps > 0:
                q_total[-1][-overlap_steps:] = 0.5 * q_total[-1][-overlap_steps:] + q_win[:overlap_steps]
                q_total.append(q_win[overlap_steps:])
            else:
                q_total.append(q_win)

        T_init = T_win_last.copy() if T_win_last.ndim == 3 else T_win_last[-1].copy()

        print(f"ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ {start_idx*dt} - {end_idx*dt} å®Œäº†ã€‚J = {J_hist[-1]:.3f}, "
              f"è¨ˆç®—æ™‚é–“ = {end_time_one_window - start_time_one_window:.2f}s")

        step = max(1, max_L - overlap)
        start_idx += step

    # æ‹¼æ¥ä¸ºå…¨å±€ qï¼Œå¹¶è£å‰ªåˆ° nt-1
    q_global = np.concatenate(q_total, axis=0)[:nt-1]
    np.save(filename, q_global)
    print(f"ç†±æµæŸqã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}, shape={q_global.shape}")
    return q_global


# %%

'''
# === Main Execution  for single calculation window === #

1. Read npy files whitch was processed based on the matlab format files from the IR camera
2. Extract the down side temperature distribution as the initial temperature distribution
3. selection the heat flux calculation domain
4. set a initial heat flux guess
5. surface heat flux calculation for a single calculation window

=== 
'''       
def main():
    start_All = time.time()

    # åˆæœŸãƒ¡ãƒ¢ãƒªçŠ¶æ³ã®ç¢ºèª
    print("=" * 80)
    print("IHCP-CGMè¨ˆç®—é–‹å§‹ - ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚·ã‚¹ãƒ†ãƒ æœ‰åŠ¹")
    print("=" * 80)
    monitor_memory_usage("è¨ˆç®—é–‹å§‹å‰", warning_threshold_gb=6.0, critical_threshold_gb=8.0)

    # å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å®‰å…¨èª­ã¿è¾¼ã¿
    data_filepath = BASE_DIR / "T_measure_700um_1ms.npy"
    try:
        T_measure_K = safe_load_large_data(data_filepath, max_size_gb=2.0, memory_check=True)
    except (MemoryError, ValueError, FileNotFoundError) as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        print("æ¨å¥¨å¯¾å¿œ:")
        print("  1. ã‚ˆã‚Šå°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§ã®ãƒ†ã‚¹ãƒˆ")
        print("  2. ãƒ¡ãƒ¢ãƒªã‚’å¢—è¨­")
        print("  3. ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²èª­ã¿è¾¼ã¿")
        return

    dt = 0.001

    T_measure_init_K = T_measure_K[0, :, :]
    T0 = np.repeat(T_measure_init_K[:, :, np.newaxis], nz, axis=2).astype(np.float64)  # shape: (ny, nx, nz)

    Y_obs = T_measure_K[:500, :, :]
    nt, ni, nj = Y_obs.shape
    nk = T0.shape[2]
    q_init = np.zeros((nt - 1, ni, nj))

    # æ‹¡æ•£æ•°ã«ã‚ˆã‚‹æ•°å€¤å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯
    # SUS304ã®ç†±ç‰©æ€§å€¤ã®ç¯„å›²ã‹ã‚‰æœ€å¤§ãƒ»æœ€å°å€¤ã‚’å–å¾—
    k_max = 34.00      # æœ€å¤§ç†±ä¼å°ç‡ [W/(mÂ·K)] at 1600Â°C
    rho_min = 7264.0   # æœ€å°å¯†åº¦ [kg/mÂ³] at 1600Â°C
    cp_min = 510.37    # æœ€å°æ¯”ç†± [J/(kgÂ·K)] at 300Â°C
    dz_min = dz.min()  # æœ€å°æ ¼å­ã‚µã‚¤ã‚º [m]

    print("æ•°å€¤å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯é–‹å§‹...")
    max_diff_num, diff_nums = check_diffusion_stability(
        dx, dy, dz_min, dt, k_max, rho_min, cp_min
    )
    print("æ•°å€¤å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯å®Œäº†ã€‚")
    print()

    # CGMè¨ˆç®—é–‹å§‹å‰ã®ãƒ¡ãƒ¢ãƒªç¢ºèª
    monitor_memory_usage("CGMè¨ˆç®—é–‹å§‹å‰", warning_threshold_gb=6.0, critical_threshold_gb=8.0)

    global_CGM_time(
        T0, Y_obs, q_init, dx, dy, dz, dz_b, dz_t, dt, rho, cp_coeffs, k_coeffs
    )

    end_All = time.time()
    print(f"Time for the whole calculation process:{end_All - start_All}")

'''ç»˜åˆ¶ä¸‹è¡¨é¢æ¸©åº¦å¯¹ç…§å›¾æ£€æŸ¥æ˜¯å¦æ­£ç¡®'''

if __name__ == "__main__":
    main()
